\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[german]{babel}
\usepackage{apacite}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{a4wide}
\usepackage[nottoc, numbib]{tocbibind}
\usepackage{natbib} 
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{siunitx}
\usepackage[singlelinecheck=false, labelfont=bf]{caption}
\usepackage{setspace}
\usepackage{rotating}
\captionsetup{font=footnotesize}



\makeatletter
\let\save@mathaccent\mathaccent
\newcommand*\if@single[3]{%
  \setbox0\hbox{${\mathaccent"0362{#1}}^H$}%
  \setbox2\hbox{${\mathaccent"0362{\kern0pt#1}}^H$}%
  \ifdim\ht0=\ht2 #3\else #2\fi
  }
%The bar will be moved to the right by a half of \macc@kerna, which is computed by amsmath:
\newcommand*\rel@kern[1]{\kern#1\dimexpr\macc@kerna}
%If there's a superscript following the bar, then no negative kern may follow the bar;
%an additional {} makes sure that the superscript is high enough in this case:
\newcommand*\widebar[1]{\@ifnextchar^{{\wide@bar{#1}{0}}}{\wide@bar{#1}{1}}}
%Use a separate algorithm for single symbols:
\newcommand*\wide@bar[2]{\if@single{#1}{\wide@bar@{#1}{#2}{1}}{\wide@bar@{#1}{#2}{2}}}
\newcommand*\wide@bar@[3]{%
  \begingroup
  \def\mathaccent##1##2{%
%Enable nesting of accents:
    \let\mathaccent\save@mathaccent
%If there's more than a single symbol, use the first character instead (see below):
    \if#32 \let\macc@nucleus\first@char \fi
%Determine the italic correction:
    \setbox\z@\hbox{$\macc@style{\macc@nucleus}_{}$}%
    \setbox\tw@\hbox{$\macc@style{\macc@nucleus}{}_{}$}%
    \dimen@\wd\tw@
    \advance\dimen@-\wd\z@
%Now \dimen@ is the italic correction of the symbol.
    \divide\dimen@ 3
    \@tempdima\wd\tw@
    \advance\@tempdima-\scriptspace
%Now \@tempdima is the width of the symbol.
    \divide\@tempdima 10
    \advance\dimen@-\@tempdima
%Now \dimen@ = (italic correction / 3) - (Breite / 10)
    \ifdim\dimen@>\z@ \dimen@0pt\fi
%The bar will be shortened in the case \dimen@<0 !
    \rel@kern{0.6}\kern-\dimen@
    \if#31
      \overline{\rel@kern{-0.6}\kern\dimen@\macc@nucleus\rel@kern{0.4}\kern\dimen@}%
      \advance\dimen@0.4\dimexpr\macc@kerna
%Place the combined final kern (-\dimen@) if it is >0 or if a superscript follows:
      \let\final@kern#2%
      \ifdim\dimen@<\z@ \let\final@kern1\fi
      \if\final@kern1 \kern-\dimen@\fi
    \else
      \overline{\rel@kern{-0.6}\kern\dimen@#1}%
    \fi
  }%
  \macc@depth\@ne
  \let\math@bgroup\@empty \let\math@egroup\macc@set@skewchar
  \mathsurround\z@ \frozen@everymath{\mathgroup\macc@group\relax}%
  \macc@set@skewchar\relax
  \let\mathaccentV\macc@nested@a
%The following initialises \macc@kerna and calls \mathaccent:
  \if#31
    \macc@nested@a\relax111{#1}%
  \else
%If the argument consists of more than one symbol, and if the first token is
%a letter, use that letter for the computations:
    \def\gobble@till@marker##1\endmarker{}%
    \futurelet\first@char\gobble@till@marker#1\endmarker
    \ifcat\noexpand\first@char A\else
      \def\first@char{}%
    \fi
    \macc@nested@a\relax111{\first@char}%
  \fi
  \endgroup
}
\makeatother
\newcommand\test[1]{%
$#1{M}$ $#1{A}$ $#1{g}$ $#1{\beta}$ $#1{\mathcal A}^q$
$#1{AB}^\sigma$ $#1{H}^C$ $#1{\sin z}$ $#1{W}_n$}



\title{Schätzgenauigkeit von Standardfehlern und deren Einfluss auf die Power bei der Analyse von hierarchischen Daten \\ \large{Ein Vergleich zwischen linearen und hierarchischen linearen Modellen}}

\author{Masterarbeit von \\ Noah Bosshart \\ Mat-Nr.: 13-747-141 \\ \\ \\ Betreut durch \\ Prof. Dr. Carolin Strobl}

\begin{document}
\setstretch{1.5}

\begin{figure}[t]
  \centering
  \includegraphics[width = 8cm]{uzh_logo}
\end{figure}

\maketitle
\thispagestyle{empty}

\newpage
\pagenumbering{Roman}
\tableofcontents

\newpage
\listoffigures

\newpage
\listoftables
\newpage


\section*{Abstract}
\newpage

\pagenumbering{arabic}
\section{Einleitung}
Hierarchische Daten treten häufig in den Sozialwissenschaften auf, unter anderem auch in der Psychologie \citep{SnijdersTomA.B2012Ma:a}. Von hierarchischen Daten wird gesprochen, wenn beispielsweise Daten von Schulkindern innerhalb verschiedener Schulklassen oder von Mitarbeitern aus mehreren Teams erhoben werden. Aber auch Daten aus Langzeitstudien werden als gruppiert bezeichnet, da mehrere Messzeitpunkte innerhalb einer Person gruppiert sind. Hierarchische Daten werden in Levels unterteilt, wobei Daten aus der niedrigsten Stufe als Level-1 Einheiten bezeichnet werden \citep{SnijdersTomA.B2012Ma:a}. Ein Beispiel für Level-1 Einheiten sind Schulkinder. Diese Schulkinder befinden sich wiederum in Klassen, die in der Hierarchiestufe höher sind und folglich als Level-2 Einheiten bezeichnet werden. Würde man nun in einer Studie nicht nur Schulkinder in Schulklassen, sondern auch  die Schulen selbst berücksichtigen, würden die Schulen als Level-3 Einheit bezeichnet werden. Die Anzahl der Levels könnte man theoretisch beliebig hoch wählen, solange es das Studiendesign erlaubt und es aus der Perspektive der Forschungsfrage sinnvoll ist. Der Einfachheit halber beschränken wir uns im Laufe dieser Arbeit aber auf hierarchische Daten mit zwei Levels. In Tabelle \ref{tab:beispiele_levels} werden einige Beispiele für Level-1 und Level-2 Einheiten aufgeführt. 
\begin{table}[h!]
\centering
\begin{threeparttable}
\caption{Beispiele für Level-1 und Level-2 Einheiten}
\begin{tabular}{ll}
\toprule
Level-1 				& Level-2 	\\
\midrule
Schulkinder 			& Klasse 	\\
Studierende 			& Studienrichtungen \\
Kinder 					& Familien 	\\
Familien 				& Nachbarschaften \\
Mitarbeiter 			& Teams \\
Teams					& Unternehmen \\
Patienten 				& Therapeuten \\
Therapeuten 			& Kliniken \\
Mehrere Messzeitpunkte 	& Person \\
\bottomrule
\end{tabular}
\label{tab:beispiele_levels}
\end{threeparttable}
\end{table}
Dabei ist zu beachten, dass sich das Level der selben Einheit je nach Untersuchungsgegenstand ändern kann. Wie man in der Tabelle \ref{tab:beispiele_levels} erkennen kann, sind Familien einmal als Level-1 und einmal als Level-2 Einheit aufgeführt. Daher ist es wichtig die Level Bezeichnung nicht als starr zu betrachtet. Vielmehr sollte man sich grundsätzlich an den niedrigsten Einheiten im Datensatz orientieren. Diesen Einheiten wird dann das Level-1 zugeschrieben.

In der Forschung ist es aus Kostengründen oder aus Gründen des Studiendesigns oft nicht möglich, solche gruppierte Datenstrukturen zu vermeiden \citep{SnijdersTomA.B2012Ma:a, woltman2012introduction}. Als eine von vielen Ursachen, die zur Entstehung solcher Datenstrukturen führt, nennen Snijders und Bosker \citeyearpar{SnijdersTomA.B2012Ma:a} \textit{multistage sampling}. Unter \textit{multistage sampling} versteht man, dass die Forschenden in der Datenerhebung auf in der Population vorhandene Gruppen zugreifen. Beispielsweise ist es Kostengünstiger zufällig 100 Schulkassen und von diesen Schulklassen wieder jeweils 10 Kinder auszuwählen als von 1000 Schulklassen jeweils nur einen Schulkind auszuwählen. Da man sonst in 1000 verschiedenen Schulklassen eine Studie durchführen müsste, um die gleiche Stichprobengrösse zu erreichen. Dieses Auswahlverfahren führt dazu, dass die erhobenen Daten nicht mehr voneinander unabhängig sind. Werden nun aus jeder Schulklasse 10 Schulkinder für eine Studie ausgewählt, ist es sehr wahrscheinlich, dass Schulkinder aus der selben Klasse zueinander ähnlichere Leistungen erzielen werden. Dieser Zusammenhang kann auf unterschiedliche Ursache zurückzuführen sein. Beispielsweise könnte die didaktischen Fähigkeiten der Lehrpersonen oder die Lichtverhältnisse im Klassenzimmer einen Einfluss auf die Leistungen der Kinder aus der selben Klasse haben. Das heisst, dass Einflussfaktoren aus unterschiedlichen Levels sich gegenseitig beeinflussen können. 

Nach Snijders und Bosker \citeyearpar{SnijdersTomA.B2012Ma:a} gibt es unterschiedliche Formen, wie diese Einheiten zueinander in Beziehung stehen können. Ein Beispiel für einen Zusammenhang auf Level-1 wäre, dass die Lernmotivation eines Schulkindes sich auf seine Schulische Leistung auswirkt. Aber auch Level-2 Einheiten können sich gegenseitig beeinflussen. Das Klima der Schulklasse könnte sich beispielsweise auf das Stressempfinden der Lehrperson auswirken. Hier wird von einem Zusammenhang innerhalb des Levels gesprochen, weil die unabhängige Variable (z.B. Lernmotivation, Klima der Schulklasse) auf dem gleichen Level wie die abhängige Variable (z.B. schulische Leistung, Stressempfinden) ist. Häufig ist es allerdings der Fall, dass es levelübergreifende Zusammenhänge zwischen den Einheiten gibt. So können beispielsweise die didaktischen Fähigkeiten einer Lehrperson (Level-2) und die Lernmotivation der Schulkinder (Level-1) die individuelle Leistung (Level-1) beeinflussen. Dieser Zusammenhang muss nicht zwingend direkt sein. Es kann auch vorkommen, dass die didaktischen Fähigkeiten den Zusammenhang zwischen Lernmotivation und individueller Leistung moderiert. In diesem Fall wird gemäss Snijders und Bosker \citeyearpar{SnijdersTomA.B2012Ma:a} von einer \textit{Cross-Level} Interaktion gesprochen.

Werden diese Abhängigkeiten in der Analyse nicht berücksichtigt, kann dies unter anderem zu einer erhöhten Fehler Typ-1 Rate führen \citep{dorman2008effect, mcneish2014analyzing}. Das heisst, dass Forschende vermehrt zu Fehlschlüssen bezüglich des Einflusses ihrer Abhängigen Variablen gelangen und irrtümlich annehmen, einen Effekt eines Verfahren gefunden zu haben, obwohl es diesen Effekt gar nicht gibt. Das Vorhandensein von hierarchischen Daten ist allerdings kein unlösbares Problem. Mit Analyseansätzen, die diese hierarchische Struktur der Daten berücksichtigen, lassen sich solche erhöhten Fehler Typ-1 Raten vermeiden. Einer dieser Ansätze ist die Multilevel Analyse, die im Fokus dieser Arbeit steht.

Diese Arbeit ist in zwei Teile unterteilt. Im ersten Teil wird das Konzept und die Theorie der Multilevel Analyse behandelt. Dabei wird kurz auf die verschiedenen Methoden eingegangen, wie man Daten auf ihre hierarchische Struktur überprüfen kann. Anschliessend wird das zugrundeliegende statistische Modell der Multlilevel Analyse vorgestellt und wie genau solche Modelle aufgebaut sind. Darauf folgend wird die Anwendung dieser Methoden in der Statistikumgebung R besprochen \citep{R}. Im zweiten Abschnitt dieser Arbeit wird eine Simulationsstudie durchgeführt, deren Ziel es ist, bereits vorhandene Ergebnisse in der Literatur zu replizieren und die Daseinsberechtigung der Mulitlevel Analyse von hierarchischen Daten zu festigen. Begleitend zu dieser Studie wird eine Shiny App programmiert \citep{shiny}, die zum einen das Konzept der Multilevel Analyse visualisiert und die Ergebnisse der hier durchgeführten Simulationsstudie interaktiv abbildet.

\section{Konzept und Anwendung von Multilevel Analyse}
Wie in der Einleitung erläutert wurde, gibt es viele Situationen in denen hierarchische Daten vorhanden sind und man zu Fehlschlüssen gelangen kann, wenn man diese Strukturen nicht berücksichtigt. In diesem Abschnitt wird nun etwas genauer auf das Konzept und die dahintersteckende Theorie der Multilevel Analyse eingegangen. Dazu wird zuerst ein simulierter Beispieldatensatz vorgestellt, anhand dessen die besprochenen Modelle erklärt werden. Als erstes wird auf die Probleme eingegangen, die durch die verwendung von einfachen linearen Modellen entstehen. Anschliessend wird das hierarchische lineare Modell (HLM) als das zugrundeliegende statistische Modell der Multilevel Analyse eingeführt. Das HLM gilt als eine Erweiterung des einfachen linearen Modells \cite{SnijdersTomA.B2012Ma:a}. Dabei werden bei HLMs in \textit{random intercept} und \textit{random intercept and slope} Modelle unterschieden. Es werden beide Modellformen besprochen und dabei wird erläutert wie die beiden Faktoren Achsenabschnitt (engl. \textit{intercept}) und Steigung (engl. \textit{slope}) zusammenhängen. Nachdem die verschiedenen Formen von HLMs besprochen worden sind, wird in einem etwas praktischeren Teil die Anwendung von Multilevel Analyse in R anhand von Beispielen etwas näher gebracht.

\subsection{Beispiel zur Theorie} \label{section:bsp_theorie}
In den folgenden Abschnitten wird die Theorie zur Analyse von hierarchischen Daten anhand eines Beispieldatensatzes erläutert. Bei dem Beispiel handelt es sich um insgesamt 150 Schulkindern aus 5 Schulklassen, die eine Mathematikprüfung geschrieben haben. Neben der erreichten Punktzahl wurde für jedes Kind zufällig ein Geschlecht, die Anzahl an gelösten Übungen, einen Wert für sozioökonomische Status und einen Intelligenzquotienten simuliert. Auf Stufe der Klasse wurden ausserdem noch die Anzahl Fenster im Klassenzimmer simuliert. Da dieser Datensatz selbst generiert wurde und aus keiner Studie entstammt, sollten Ergebnisse, die aus diesen Berechnungen entstehen nicht weiter interpretiert werden. Eine genaue Erläuterung wie dieser Datensatz generiert wurde, ist im Abschnitt \ref{section:generierung_daten} über die Generierung von hierarchischen Daten zu finden. In Tabelle \ref{tab:beispiel_theorie} sind zur Veranschaulichung dieser Daten eine Auswahl von 10 Schulkindern aufgeführt.

\begin{table}[ht]
\centering
\begin{threeparttable}
\caption{Ausschnitt des simulierten Datensatzes} 
\begin{tabular}{cccccccc}
  \toprule
 Schulkind Nr. & Klasse & Übungen & Punktzahl & Geschlecht & Anz. Fenster & SES & IQ \\ 
  \midrule
101 & 4 & 17 & 21 & m & 3 & 16 & 104 \\ 
  75 & 3 & 7 & 29 & m & 8 & 27 & 112 \\ 
  126 & 5 & 23 & 26 & w & 4 & 14 & 110 \\ 
  14 & 1 & 10 & 29 & m & 4 & 21 & 84 \\ 
  137 & 5 & 16 & 18 & w & 4 & 17 & 109 \\ 
  100 & 4 & 7 & 16 & w & 3 & 20 & 98 \\ 
  78 & 3 & 28 & 44 & w & 8 & 23 & 105 \\ 
  121 & 5 & 25 & 33 & w & 4 & 21 & 99 \\ 
  16 & 1 & 7 & 24 & w & 4 & 30 & 77 \\ 
  116 & 4 & 14 & 29 & m & 3 & 19 & 90 \\ 
   \bottomrule
\end{tabular}
\label{tab:beispiel_theorie}
\end{threeparttable}
\end{table}

Betrachtet man die Variablen des Datensatzes, könnte man daraus schliessen, dass es sich um einen hierarchischen Datensatz mit zwei Levels handelt. Zu den Level-1 Variablen gehören alle Variablen die sich auf der Stufe der tiefsten Einheit (Schulkinder) befinden. Dazu zählen die Anzahl gelösten Übungen, die erreichte Punktzahl, das Geschlecht, der sozioökonomische Status und der IQ. Die beiden anderen Variablen Klasse und die Anzahl Fenster im Klassenzimmer gehören zur Level-2 Ebene. Um allerdings genau festzulegen, ob die hierarchische Struktur einen Einfluss auf die erreichte Punktzahl hat, benötigt es die Berechnung weiterer Kennwerte. 

\subsection{Intraklassen Korrelation} \label{section:icc}
Der Einfluss einer hierarchischen Struktur auf eine abhängige Variable kann durch die Intraklassen Korrelation (IKK) beschrieben werden. Die Intraklassen Korrelation beschreibt den Grad der Ähnlichkeit von Level-1 Einheiten innerhalb einer Level-2 Einheit und kann als Verhältnis der Varianz zwischen den Level-2 Einheiten und der Gesamtvarianz beschrieben werden \citep{FieldAndy2013DsuR, SnijdersTomA.B2012Ma:a, twisk_2006}. Diese Varianzen ergeben sich gemäss Snijders und Bosker \citeyearpar{SnijdersTomA.B2012Ma:a} aus dem \textit{random effects ANOVA} Modell, das bei der Modellierung von Multilevel Modellen oft auch als leeres Modell bezeichnet wird:
\begin{equation} \label{eq:empty_model}
Y_{ij} = \mu + U_{j} + R_{ij}
\end{equation}
Die abhängige Variable $Y_{ij}$ beschreibt in unserem Beispiel die erreichte Punktzahl des Schulkindes $i$ aus der Klasse $j$. Der Gesamtmittelwert aller Schulkinder wird mit $\mu$ bezeichnet, wobei $U_{j}$ die zufällige Abweichung einer Klasse $j$ und $R_{ij}$ die zufällige Abweichung eines Schulkindes $i$ der Klasse $j$ von diesem Gesamtmittelwert beschreiben. Dabei ist zu beachten, dass der Erwartungswert beider Zufallsvariablen $U_{j}$ und $R_{ij}$ als 0 angenommen wird. Die Varianz von $U_{j}$ wird als \textit{between-group variance} $\tau_{0}^2$ und von $R_{ij}$ als \textit{within-group variance} $\sigma^2$ bezeichnet.

Bei der IKK wird von einer Korrelation gesprochen, da es sich um die Korrelation zwischen zweier zufällig gewählter Level-1 Einheiten aus der selben Level-2 Einheit handelt. Bezogen auf unser Beispiel gibt die IKK an, wie stark sich Schulkinder aus der selben Klasse bezüglich ihrer erreichten Punktzahl ähneln. Ist die Korrelation zwischen den Schulkindern hoch, kann man davon ausgehen, dass die Klasse als Level-2 Einheit einen bedeutenden Anteil an der Gesamtvarianz erklärt. Ist die Korrelation niedrig hat die Klassenzugehörigkeit eher einen kleineren Einfluss auf die Prüfungsleistung. Dieser Zusammenhang wird etwas klarer, wenn man ihn anhand der Formel zur Berechnung der Intraklassen Korrelation Koeffizienten $\rho_{I}$ erklärt:
\begin{equation} \label{eq:icc}
\rho_{I} = \dfrac{\tau_{0}^{2}}{\tau_{0}^{2} + \sigma^{2}}
\end{equation} 
Dabei beschreibt $\tau_{0}^2$ die \textit{between-group variance}. In unserem Beispiel wäre das die Varianz der erreichten Punktzahl zwischen den verschiedenen Klassen. Die Gesamtvarianz setzt sich aus der \textit{between-group variance} und der \textit{within-group variance} zusammen. Die Varianz innerhalb der Klassen wird, wie bereits erwähnt, mit $\sigma^2$ bezeichnet. Besteht nun innerhalb der Klassen eine kleine Varianz zwischen den Ergebnissen der Schulkinder ergibt sich eine grössere Intraklassen Korrelation. Steigt die Varianz innerhalb der Klassen an, wird der Nenner der Formel grösser und mit einem wachsenden Nenner, verringert sich die Intraklassen Korrelation.
<<echo = FALSE, error=FALSE, warning=FALSE, message=FALSE>>=
library("formatR")
library("lme4")
options(digits = 2)
ml_data <- readRDS(file = "dataset_theory")
lm0 <- lmer(punktzahl ~ (1|klasse), data = ml_data, REML = FALSE)

var_between <- VarCorr(lm0)$klasse[1,1]
var_within <- sigma(lm0)^2
var_tot <- var_between + var_within

icc <- var_between / (var_tot)
icc_p <- round(icc * 100, digits = 0)

ols <- lm(punktzahl ~ klasse, data = ml_data)
pvalue <- anova(ols)[1,5]
@
Um nun zu überprüfen, ob in unserem Datensatz überhaupt abhängige hierarchische Strukturen vorhanden sind, können wir die IKK für unser Datensatz berechnen. Da die Populationswerte oft nicht bekannt sind, gibt es viele statistische Verfahren, um Schätzer für die nötigen Varianzen zu berechnen. Da diese Verfahren den Umfang dieser Arbeit sprengen würden und es viele Statistikprogramme gibt, die diese Berechnungen mit präzieseren Methoden durchführen können, werden in dieser Arbeit nur die computerbasierten Verfahren behandelt. Die restlichen Verfahren können aber in der gängigen Literatur zur Multilevel Analyse nachgeschlagen werden \citep[z.B.][]{SnijdersTomA.B2012Ma:a}. Mit Hilfe des Statistikprogramms R wurden nun alle nötigen Varianzen geschätzt und in die Formel \eqref{eq:icc} eingesetzt\footnote{Die Berechnung dieser Schätzer in R werden in Abschnitt \ref{section:ml_in_R} erläutert.}:
\begin{equation} \label{eq:icc_calc}
\rho_{I} = \dfrac{\Sexpr{var_between}}{\Sexpr{var_between} + \Sexpr{var_within}} = \Sexpr{icc}
\end{equation}
Die daraus resultierende Intraklassen Korrelation von $\rho_{I} = \Sexpr{icc}$ weist darauf hin, dass \Sexpr{icc_p}\% der Varianz in der erreichten Punktzahl in der Mathematikprüfung durch die Klassenzugehörigkeit erklärt wird. Gemäss Hedges und Hedberg \citeyearpar{hedges&hedberg:2007} werden in den Erziehungswissenschaften oft Intraklassen Korrelationen von 0.10 und 0.25 gefundenn. Folglich liegt unsere IKK von $\rho_{I} = \Sexpr{icc}$ in einem realistischen Bereich. Eine Intraklassen Korrelation von $\rho_{I} > 0$ bedeutet aber noch nicht, dass eine Multilevel Analyse notwendig ist. Unter der Annahme, dass die zufällige Abweichungen der Schulkinder $R_{ij}$ normalverteilt sind, kann gemäss Snijders und Bosker \citeyearpar{SnijdersTomA.B2012Ma:a} eine Varianzanalyse durchgeführt werden, um zu untersuchen, ob Gruppenunterschiede vorhanden sind. In unserem Fall führte die Varianzanalyse zu einem hoch signifikantem Ergebnis ($p<.001$) und es bestehen folglich Unterschiede zwischen den Klassen. Wir wissen nun nicht nur, wie viel Varianz durch die Klasse erklärt wird sondern auch, dass diese sich signifikant Unterscheiden. Folglich sollten diese Daten mit einem Multilevel Ansatz analysiert werden.

\subsection{Lineare Modelle} \label{section:linear_model}
Bevor wir uns mit den hierarchischen linearen Modellen beschäftigen, werden die Grundlagen der linearen Modellen (LM) kurz erläutert und aufgezeigt zu welchen Problemen es führen kann, wenn die hierarchische Datenstruktur ignoriert wird. Gemäss Gelman und Hill \citeyearpar{andrew_data} ist die lineare Regression eine Methode, die Veränderungen von Durchschnittswerten einer abhängigen Variablen durch eine lineare Funktion von Prädiktoren beschreibt. In etwas einfacheren Worten ausgedrückt, versucht die lineare Regression durch die Kombination von unabhängigen Variablen die mittlere Ausprägung einer abhängigen Variable zu beschreiben. Ein lineares Regressionsmodell kann wie folgt formuliert werden:
\begin{equation} \label{eq:ols_model}
y_{i} = \beta_{0} + \beta_{1}x_{i1} + \dots + \beta_{ik}x_{ik} + \epsilon_{ij}, \text{ für } i = 1, \dots, n \text{ und } \epsilon_{ij} \sim \mathcal{N}(0,\sigma^{2})
\end{equation}
Dabei ist $y_{i}$ die abhängige Variable von der Person $i$. In unserem Beispiel wäre das die erreichte Punktzahl des Schulkindes $i$. $\beta_0$ beschreibt den Achsenabschnittes (\textit{intercept}) und ist die durchschnittlich erreichte Punktzahl in der Mathematikprüfung, wenn keine weitere Prädiktoren berücksichtigt werden. Die weiteren Regressionskoeffizienten $\beta_{1}$ bis $\beta_{k}$ beschreiben für jede unabhängige Variable $x_{i1}$ bis $x_{ik}$ wie stark $y_{i}$ des $i$-ten Schulkindes bei einer Zunahme um eine Einheit ansteigt. Die Regressionskoeffizienten $\beta_{1}$ bis $\beta_{k}$ beschreiben also die Steigung (\textit{slope}). Möchten wir in unserem Beispiel die erreichte Punktzahl durch die Anzahl gelöster Übungsaufgaben beschreiben, wäre $x_{i1}$ die Anzahl gelöster Übungsaufgaben des $i$-ten Schulkindes und der dazugehörige Regressionskoeffizient $\beta_{1}$ gibt die Zunahme der Punktzahl in der Mathematikprüfung an. Der letzte Koeffizient des Regressionsmodells ist $\epsilon_{ij}$ und wird als zufälliger Fehler oder Residuum bezeichnet. Das Residuum ist die normal verteilte zufällige Abweichung jedes $i$-ten Schulkindes, mit einem Erwartungswert von 0 und Varianz von $\sigma^{2}$. Das bedeutet, dass es zwischen den Kindern zufällige Unterschiede in ihrer Prüfungsleistung gibt, die nicht durch das Regressionsmodell erfasst werden. Diese Unterschiede sind im Mittel aber 0. 

Möchte man mit einem linearen Regressionsmodell die Daten unseres Beispiels untersuchen gibt es zwei Möglichkeiten. Die erste Möglichkeit ist die Aggregation, die häufig in den Sozialwissenschaften angewandt wird \citep{SnijdersTomA.B2012Ma:a}. Bei dieser Methode werden Mittelwerte für jede Klasse berechnet und anhand dieser wird dann ein lineares Modell erstellt. Die zweite Möglichkeit ist die Disaggregation, bei der die Klassenstruktur aufgelöst wird und alle 150 Schulkinder als unabhängige Werte in die Analyse einfliessen.

\subsubsection{Aggregation}
Wie bereits erwähnt, werden bei der Aggregation für jede Level-2 Einheit Mittelwerte berechnet, die später in das Regressionsmodell einfliessen. Ausgehend von unserem Beispiel könnte man sich nun für den Zusammenhang zwischen der Anzahl gelöster Übungsaufgaben und der erreichten Punktzahl in der Mathematikprüfung interessieren. In Tabelle \ref{tab:aggregation} sind die relevanten Mittelwerte für jede der fünf Schulklassen aufgelistet.

\begin{table}[b]
\centering
\begin{threeparttable}
\caption{Mittlere Anzahl gelöster Übungsaufgaben und erreichte Punktzahl}
\begin{tabular}{ccc}
  \toprule
Klasse & Übungen & Punktzahl \\ 
  \midrule
1 & 13.1 & 21.5 \\ 
2 & 12.8 & 29.3 \\ 
3 & 13.5 & 30.7 \\ 
4 & 15.7 & 25.6 \\ 
5 & 17.5 & 24.7 \\ 
   \bottomrule
\end{tabular}
\label{tab:aggregation}
\end{threeparttable}
\end{table}

Wird nun anhand dieser aggregierter Werte überprüft, wie genau die erreichte Punktzahl eines Schulkindes mit der Anzahl an gelösten Übungsaufgaben zusammenhängt, entstehen mehrere Probleme, die zu Verzerrungen und Fehlschlüssen führen können. Zum einen verändert sich die Forschungsfrage, da sich durch die Aggregation der Daten der Fokus von der Level-1 Ebene auf die Level-2 Ebene verschiebt \citep{SnijdersTomA.B2012Ma:a, woltman2012introduction}. Die abhängige Variable ist nun nicht mehr die erreichte Punktzahl jedes einzelnen Schulkindes, sondern die durchschnittlich erreichte Punktzahl einer Schulklasse. Ein weiteres Problem ist der Verlust von Variabilität, die durch individuelle Unterschiede zwischen den Schulkindern entsteht. Dieser Verlust an Variabilität beträgt nach Raudenbush und Bryk 80-90\% und kann zu massiven Fehlschlüssen über den Zusammenhang der Variablen führen \citeyearpar{raudenbush2002hierarchical}. 

Betrachtet man die Regressionsgerade in Abbildung \ref{fig:aggregiert}, sieht man, dass ein höhere Anzahl an gelöster Übungsaufgaben mit einer tieferen durchschnittlich erreichten Punktzahl zusammenhängt. Folglich könnte man daraus schliessen, dass dies auch auf Ebene der Schüler zutrifft und eine Erhöhte Anzahl an gelösten Übungsaufgaben mit einer tieferen Punktzahl in der Prüfung einhergeht. Diese Schlussfolgerung ist allerdings unzulässig, da man nicht von einer Korrelation zweier Level-2 Variablen auf den Zusammenhang von Level-1 Variablen schliessen darf \citep{SnijdersTomA.B2012Ma:a}.  Diese fehlerhafte Schlussfolgerung wird auch als ökologischer Fehlschluss bezeichnet \citep{robinson2009ecological}.

\begin{figure}[b!]
\centering
\captionsetup{width=8cm}
\includegraphics[width = 8cm, height = 8cm]{aggregation}
\caption{Zusammenhang zwischen der durchschnittlich gelösten Anzahl an Übungsaufgaben und der durschnittlich erreichten Punktzahl pro Klasse}
\label{fig:aggregiert}
\end{figure}

Die Analyse mittels Aggregation führt folglich nicht zu einem zufriedenstellenden Ergebnis und ist aufgrund der besprochenen Einschränkungen nicht geeignet, um Zusammenhänge auf Level-1 Ebene zu untersuchen.

\subsubsection{Disaggregation} \label{section:disaggregation}
Die zweite Möglichkeit um hierarchsiche Daten mit einem linearen Regressionsmodell zu untersuchen ist die Disaggregation. Wie bereits angedeutet werden bei der Disaggregation alle Level-2 Variablen auf Level-1 Einheiten verteilt. 

In unserem Beispiel werden also alle Schulkinder als von einander unabhängige Datenpunkte in die Analyse mit einbezogen. Dazu werden jedem Schulkind aus der selben Klasse die gleichen Werte der Level-2 Variablen zugeschrieben. In Tabelle \ref{tab:beispiel_theorie} aus Abschnitt \ref{section:bsp_theorie} kann man dieses Vorgehen bei den beiden Level-2 Variablen \textit{Klasse} und \textit{Fenster} beobachten. Durch diese Disaggregation von Level-2 Variablen auf Level-1 Einheiten werden Datensätze künstlich vergrössert und mögliche Variabilität, die zwischen den Level-2 Variablen besteht, wird ignoriert \citep{SnijdersTomA.B2012Ma:a, woltman2012introduction}. Folglich wird die geteilt Varianz zwischen Level-1 Einheiten nicht berücksichtigt und die Annahme, dass Fehler voneinander unabhängig sind, ist verletzt. Das führt dazu, dass die Effekte von Level-1 und Level-2 Variablen auf die abhängige Variable nicht voneinander getrennt werden können \citep{woltman2012introduction}. In unserem Beispiel würde das bedeuten, dass man den Einfluss der Anzahl an gelösten Übungsaufgaben nicht vom Einfluss der Klasse trennen kann. Ein weiteres Problem das durch Disaggregation entsteht, ist dass Abhängigkeiten innerhalb des Datensatzes unberücksichtigt bleiben \citep{woltman2012introduction}. Dies führt zu einer weiteren verletzten Annahme über die Unabhängigkeit von Beobachtungen. Die Verletzung dieser Annahme führt dazu, dass statistische Schätzer ungenau werden \citep{andrew_data, SnijdersTomA.B2012Ma:a, woltman2012introduction}.

\begin{figure}[t!]
\centering
\includegraphics[width = \textwidth]{disaggregation_combined}
\caption{Zusammenhang zwischen der Anzahl gelöster Übungsaufgaben und erreichte Punktzahl mittels Disaggregation und Anwendung dieses Zusammenhangs auf jede der fünf Klassen}
\label{fig:disaggregation}
\end{figure}

Auf der linken Seite der Abbildung \ref{fig:disaggregation} befindet sich die Regressionsgerade, die durch ein lineares Regressionsmodell entsteht, wenn man mit einem disaggregierten Datensatz arbeitet. Anhand dieser Regressionsgerade besteht ein positiver Zusammenhang zwischen der Anzahl gelöster Übungsaufgaben und der erreichten Punktzahl in der Mathematikprüfung, so dass die erreichte Punktzahl mit steigender Anzahl an gelöster Übungsaufgaben zunimmt. Wie vorhin bereits erwähnt, wird in dieser Analyse aber nicht berücksichtigt, dass die Schulklasse selbst einen Effekt auf die erreicht Punktzahl haben kann. Dieser Effekt wird klar, wenn man die rechte Seite der Abbildung \ref{fig:disaggregation} betrachtet. Für jede der fünf Klassen wurde die selbe Regressionsgerade, die aus dem disaggregierten Datensatz entsteht, über die Daten gelegt. Man kann relativ einfach erkennen, dass es gewisse Klassen gibt, bei  denen mehr Schulkinder über oder unter der Regressionsgerade liegen. Des weiteren kann man erkennen, dass es nicht optimal ist, wenn für alle Klassen die selbe Steigung der Regressionsgerade verwendet wird. Betrachten wir beispielsweise die zweite Klasse, kann man erkennen, dass diese Schulkinder einen viel stärkeren Zusammenhang zwischen gelösten Übungsaufgaben und erreichter Punktzahl verzeichnen als die erste Klasse. Man könnte nun mit Hilfe einer Dummy-Kodierung den Einfluss von Klassen berücksichtigen, dazu müsste aber für jede Klasse einen zusätzlichen Parameter in das Modell aufgenommen werden. Da es grundsätzlich erstrebenswert ist, möglichst sparsame Modelle zu bilden ist auch dies keine optimale Lösung. Die Aggregation als auch die Disaggregation der Daten unterliegen massiven Einschränkungen und führen zu keinem zufriedenstellenden Ergebnis. Es erfordert folglich ein weiteres Modell, das Zusammenhänge innerhalb und zwischen Level-2 Einheiten abbilden kann ohne sich dabei auf eine Analyseinheit festzulegen.

\subsection{Hierarchische Linearen Modelle}
In den letzten Abschnitten wurde angenommen, dass sich die Regressionskoeffizienten $\beta_0$ und $\beta_1$ feste Werte sind, die sich nicht verändern. In Abbildung \ref{fig:disaggregation} aus dem vorherigen Abschnitt konnte man aber erkennen, dass diese Annahme nicht in allen Fällen zu einem erwünschten Ergebnis führt. In unserem Beispiel gibt es offensichtlich Klassen, die eine über- oder unterdurchschnittliche erreichte Punktzahl verzeichnen. Man kann nun annehmen, dass diese Regressionskoeffizienten zufällig sind. In diesem Kontext versteht man unter zufällig aber nicht, dass die Koeffizienten irgendwie gewählt werden können, sondern vielmehr, dass diese Koefizienten variieren können. 

In den folgenden Abschnitten werden nun hierarchische lineare Modelle besprochen, mit denen es möglich ist solche zufällige Koeffizienten zu schätzen. Als erstes wird das \textit{Random Intercept} Modell vorgestellt. Dieses Modell geht davon aus, dass die Höhe des Achsenabschnittes (\textit{intercept}) von der Gruppenzugehörigkeit abhängt und schätzt folglich mehrere verschiedene Achsenabschnitte. Das zweite besprochenen Modell ist das \textit{Random Intercept and Slope} Modell, bei dem sich nicht nur der Achsenabschnitt, sondern auch die Steigung (\textit{slope}) in Abhängigkeit der Gruppe unterscheidet. Dabei wird der Fokus vor allem darauf gesetzt, dass das Konzept von hierarchischen linearen Modellen verstanden wird. Wie genau solche HLMs mit R berechnet und analysiert werden, wird im Abschnitt \ref{section:ml_in_R} behandelt. 

\subsubsection{\textit{Random Intercept} Modell} \label{section:random_intercept_model}
<<echo = FALSE, error=FALSE, warning=FALSE, message=FALSE>>=
options(digits = 2)
ml_data <- readRDS(file = "dataset_theory")
model <- lmer(punktzahl ~ uebung + (1|klasse), data = ml_data)

u03 <- ranef(model)$klasse[3,1]
u01 <- ranef(model)$klasse[1,1]
gamma00 <- fixef(model)[1]
beta03 <- gamma00 + u03
beta01 <- gamma00 + u01
@
Das \textit{Random Intercept} Modell ermöglicht es für jede Gruppe unterschiedliche Achsenabschnitte zu schätzen. Die einfachste Form eines \textit{Random Intercept} Modells ist ein Modell, das nur den Koeffizienten für den Achsenabschnitt $\beta_{0j}$ und das Residuum $\epsilon_i$ enthält. Dieses Modell wird wie folgt beschrieben:
\begin{equation}
\begin{split}	
\text{Level 1:} & \qquad y_{ji} 	= \beta_{0j} + \epsilon_{ij}\\
\text{Level 2:} & \qquad \beta_{0j} = \gamma_{00} + U_{0j}
\end{split}	
\end{equation} 
Bei dieser Darstellung handelt es sich um die hierarchische Notation der Gleichung, da die einzelnen Gleichungen gleich dem dazugehörigen Level zugeordnet werden. Dies wird klarer, wenn man es in Bezug zu unserem Beispiel betrachtet. Auf Level-1 befindet sich die Regressionsgleichung für die erreichte Punktzahl jedes einzelnen Schulkindes $i$ aus der Klasse $j$. Dabei kann man erkennen, dass der Regressionskoeffizient $\beta_{0j}$ von der Klasse $j$ abhängt und folglich für jede Klasse einen anderen Wert einnimmt. Da die Klasse eine Level-2 Variable ist, befindet sich die Gleichung für $\beta_{0j}$ auf Level-2. Dabei ist $\gamma_{00}$ der Gesamtmittelwert und $U_{0j}$ die zufällige Abweichung der Klasse $j$ vom Gesamtmittelwert. Substituiert man die Gleichung von Level-2 in die Gleichung von Level-1 gelangt man zur flachen Notation dieses \textit{Random Interceot} Modells:
\begin{equation}
\begin{split}
y_{ji} 	& = \beta_{0j} + \epsilon_{ij}\\
		& = \gamma_{00} + U_{0j} + \epsilon_{ij}
\end{split}
\end{equation}
Diese Gleichung entspricht dem leeren Modell aus Abschnitt \ref{section:icc}, anhand dessen man die Intraklassen Korrelation berechnet. Ähnlich wie bei der normalen linearen Regression können diesem Modell nun weitere Variablen hinzugefügt werden, um die Varianz in der erreichten Punktzahl des Schulkindes $i$ aus der Klasse $j$ zu erklären. In unserem Beispiel ergänzen wir das Modell mit nur einer weiteren Varialbe $x_{ij}$, die der Anzahl gelöster Übungsaufgaben entspricht:
\begin{equation} \label{eq:random_intercept_model}
\begin{split}	
 \text{Level 1:}  	\qquad 	y_{ji} 		& = \beta_{0j} + \beta_{1}x_{ij} + \epsilon_{ij}\\
 \text{Level 2:} 	\qquad 	\beta_{0j} 	& = \gamma_{00} + U_{0j}\\
 							\beta_{1} 	& = \gamma_{10}
\end{split}	
\end{equation} 
Da es sich hier um ein \textit{Random Interceot} Modell handelt, bleibt die Steigung für alle Klassen gleich. Dies kann man an der Gleichung des Koeffizienten $\beta_{1}$ erkennen, da es keine zufällige Abweichung in Abhängigkeit der Klasse $j$ von der Gesamtsteigung $\gamma_{10}$ gibt. Werden nun aus \eqref{eq:random_intercept_model} die beiden Gleichungen auf Level-2 in die Gleichung auf Level-1 eingesetzt, gelangen wir wieder zur flachen Notation des \textit{Random Intercept} Modells:
\begin{equation}
\begin{split}
y_{ji} 	& = \beta_{0j} + \beta_{1}x_{ij} + \epsilon_{ij} \\
		& = \gamma_{00} + U_{0j} + \gamma_{10}x_{ij} + \epsilon_{ij} \\
		& = \gamma_{00} + \gamma_{10}x_{ij} + U_{0j} + \epsilon_{ij}
\end{split}
\end{equation}

In Abbildung \ref{fig:random_intercept} kann man nun die Graden für jede einzelne Klasse erkennen. Die rote Gerade entspricht der linearen Regressionsgerade, die durch die Disaggregation entsteht und wird hier als Vergleichswert zu den anderen Geraden verwendet. Auf der linken Seite der Abbildung erkennt man relativ schnell, dass es bedeutende Unterschiede zwischen den Klassen gibt. Werden die Geraden für jede einzelne Klasse betrachtet, erhält man einen Überblick über das Leistungslevel der verschiedenen Klassen. Beispielsweise kann man erkennen, dass die Klassen eins und fünf eher tiefere und die Klassen zwei und drei eher höhere Punktzahlen erreichen. Diese Unterschiede kommen durch die unterschiedliche Ausprägungen der zufälligen Abweichungen $U_{0j}$ zustande. Für die Klasse 3 ergibt sich beispielsweise aus unserem \textit{Random Intercept} Modell einen Schätzer für die zufällige Abweichung von $U_{03} = \Sexpr{u03}$ und für den Gesamtmittelwert $\gamma_{00} = \Sexpr{gamma00}$. Setzt man diese beiden Werte in die Gleichung aus \eqref{eq:random_intercept_model} erhält man den klassenspezifischen Achsenabschnitt $\beta_{03}$:
\begin{equation}
\beta_{03} = \Sexpr{gamma00} + \Sexpr{u03} = \Sexpr{beta03}
\end{equation} 
Schulkinder der Klasse 3 erreichen bei $0$ gelösten Übungsaufgaben im Mittel eine Punktzahl von $\Sexpr{beta03}$. Für Klasse 1 lässt sich ihr Achsenabschnitt $\beta_{01}$ genau gleich bestimmen. Aus der klassenspezifischen Abweichung $U_{01} = \Sexpr{u01}$ und dem Gesamtmittelwert von $\gamma_{00} = \Sexpr{gamma00}$ ergibt sich ein Achsenabschnitt von $\beta_{01} = \Sexpr{beta01}$. Schulkinder aus Klasse eins erreichen bei 0 gelösten Übungsaufgaben im Mittel also eine tiefere Punktzahl als Schulkinder aus Klasse 3. Diese Aussage stimmt ebenfalls mit den Geraden aus Abbildung \ref{fig:random_intercept} überein. Das Prinzip des Zusammenhangs zwischen der zufälligen Abweichung $U_{0j}$ und dem Gesamtmittelwert $\gamma_{00}$ kann also ähnlich wie bei einer Dummy-Kodierung verstanden werden. Dabei ist der Gesamtmittelwert die Referenzkategorie, von der jede Klasse um $U_{0j}$ abweicht.

\begin{figure}[t!]
\centering
\includegraphics[width = \textwidth]{random_intercept}
\caption{Zusammenhang zwischen der Anzahl gelöster Übungsaufgaben und der erreichten Punktzahl unter Berücksichtigung der Klassenzugehörigkeit}
\label{fig:random_intercept}
\end{figure}

Ebenfalls kann man beobachten, dass die Geraden des hierarchischen linearen Modells besser zu den Daten passen. Dies wird etwas klarer, wenn man die Residuenplots des \textit{Random Intercept} Modells und des normalen linearen Modells vergleicht. In Abbildung \ref{fig:resid_lm_rim} sind die beiden Residuenplots abgebildet. Auch wenn die Unterschiede nicht all zu gross sind, kann man erkennen, dass es beim \textit{Random Intercept} Modell weniger grosse Abweichungen gibt zwischen den tatsächlich beobachteten Werten und den vom Regressionsmodell erwarteten Werten. Allerdings fällt beim Residuenplot des \textit{Random Intercept} Modells auf, dass an den Endpunkten die Residuen nicht mehr um den Nullpunkt verteilt sind, beim linearen Modell allerdings schon. Die Ursache dafür besteht darin, dass die Residuen nun für jede einzelne Regressionsgerade der Klassen berechnet werden. Da bei dem normalen linearen Modell die Residuen alle nur an einer Geraden berechnet werden, gleichen sich die Residuen der Schulkinder aus leistungsstärkeren Klassen mit den Kindern aus leistungsschwächeren Klassen aus. Betrachtet man in Abbildung \ref{fig:random_intercept} die rechte Seite, passen die Regressionsgeraden des \textit{Random Intercept} Modells besser zu den Daten als das lineare Modell. Allerdings gibt es immer noch Schulkinder, die noch nicht optimal durch die Gerade beschrieben werden. Bei der zweiten und dritten Klasse erreichten beispielsweise Schulkinder, die viele Übungen gelöst haben eine noch viel höhere Punktzahl als vom Modell angenommen wird. Diese Ungenauigkeit führt folglich zu einer unpassenden Verteilung der Residuen an den Endpunkten. Anscheinend gibt es in unserem Datensatz Klassen, bei denen die Schulkinder einen stärkeren oder schwächeren Anstieg der erreichten Punktzahl bei steigender Anzahl gelöster Übungsaufgaben verzeichnen. Daraus könnte man nun folgern, dass sich nicht nur der Achsenabschnitt zwischen den Klassen unterscheidet, sondern auch die Steigung.

\begin{figure}[t!]
\centering
\includegraphics[width = \textwidth]{residuen_lm_rim}
\caption{Residuenplot des linearen Modells und des \textit{Random Intercept} Modells}
\label{fig:resid_lm_rim}
\end{figure}

\subsubsection{\textit{Random Intercept and Slope} Modell} \label{section:random_intercept_slope_model}
<<echo = FALSE, error=FALSE, warning=FALSE, message=FALSE>>=
options(width=60)
options(digits = 2)
ml_data <- readRDS(file = "dataset_theory")
model <- lmer(punktzahl ~ uebung + (uebung|klasse), data = ml_data)

u13 <- ranef(model)$klasse[3,2]
u11 <- ranef(model)$klasse[1,2]
gamma10 <- fixef(model)[2]
beta13 <- gamma10 + u13
beta11 <- gamma10 + u11
@
Im letzten Abschnitt wurde das \textit{Random Intercept} Modell besprochen und aufgezeigt, dass man durch die Hinzunahme von variierenden Achsenabschnitten eine bessere Passung zwischen dem Modell und den Daten erreicht. Um eine noch bessere Passung zu erreichen und genauere Vorhersagen zu treffen kann man nun nicht nur den Achsenabschnitt, sondern auch die Steigung variieren lassen. Dies führt zum \textit{Random Intercept and Slope} Modell, das die Interaktion zwischen Klassenzugehörigkeit und der Anzahl gelöster Übungsaufgabe berücksichtigt. Der Regressionskoeffizient $\beta_{1}$ aus dem \textit{Random Intercept} Modell \eqref{eq:random_intercept_model} ist nun von der Klasse $j$ abhängig und wird durch die zufällige Abweichung $U_{1j}$ erweitert. Dies führt zum folgenden Modell in der hierarchischen Notation:
\begin{equation} \label{eq:random_intercept_slope_model}
\begin{split}	
 \text{Level 1:}  \qquad y_{ji} & = \beta_{0j} + \beta_{1}x_{ij} + \epsilon_{ij}\\
 \text{Level 2:} \qquad \beta_{0j} & = \gamma_{00} + U_{0j}\\
 \beta_{1j} & = \gamma_{10} + U_{1j}
\end{split}	
\end{equation} 
Durch Einsetzen und Umformen erhalten wir wieder die flache Notation unseres Modells:
\begin{equation} \label{eq:flat_random_intercept_slope_model}
\begin{split}	
y_{ji} & = \beta_{0j} + \beta_{1}x_{ij} + \epsilon_{ij}\\
& = \gamma_{00} + U_{0j} + (\gamma_{10} + U_{1j})x_{ij} + \epsilon_{ij}\\
& = \gamma_{00} + \gamma_{10}x_{ij} + U_{0j} + U_{1j}x_{ij} + \epsilon_{ij}
\end{split}	
\end{equation} 
Dabei wurde die Gleichung so umgeformt, dass der erste Teil $\gamma_{00} + \gamma_{10}x_{ij}$ die jeweiligen Gesamtmittelwerte enthält. Diese Werte sind unveränderbar und werden folglich als fester Teil des Modells bezeichnet. Der zweite Teil der Gleichung mit $U_{0j} + U_{1j}x_{ij} + \epsilon_{ij}$ wird als zufälliger Teil bezeichnet, weil er alle veränderbaren Werte enthält. Der Term $U_{1j}x_{ij}$ beschreibt die zufällige Interaktion zwischen Gruppenzugehörigkeit und der Variable $x_{ij}$. Bezogen auf unser Beispiel bedeutet dieser Term, wie stark und in welche Richtung sich die erreichte Punktzahl verändert in Abhängigkeit der Klassenzugehörigkeit und der Anzahl gelöster Übungen. 
\begin{figure}[ht!]
\centering
\includegraphics[width = \textwidth]{random_intercept_slope}
\caption{Zusammenhang zwischen der Anzahl gelöster Übungsaufgaben und der erreichten Punktzahl unter Berücksichtigung der Klassenzugehörigkeit und deren Interaktion mit der Anzahl gelöster Übungsaufgaben}
\label{fig:random_intercept_slope}
\end{figure}
In Abbildung \ref{fig:random_intercept_slope} ist diese zufällige Interaktion einfach zu erkennen. Für gewisse Klassen nimmt die Zufallsvariable $U_{1j}$ eine positiven und für andere einen negativen Wert ein. Dies spiegelt sich wiederum in klassenspezifischen Steigungen $\beta_{1j}$ die höher oder tiefer als die mittlere Steigung $\gamma_{10}$ sind. Betrachten wir die Klasse 3 unseres Beispiels. Das \textit{Random Intercept and Slope} Modell schätzt für diese Klasse eine zufällige Abweichung $U_{13} = \Sexpr{u13}$ von der mittleren Steigung $\gamma_{10} = \Sexpr{gamma10}$. Setzt man nun diese beide Werte in die Gleichung für $\beta_{1j}$ aus \eqref{eq:random_intercept_slope_model} ein erhält man die klassenspezifische Steigung $\beta_{13}$.
\begin{equation} \label{eq:beta1_example}	
\beta_{13} = \Sexpr{gamma10} + \Sexpr{u13} = \Sexpr{beta13}
\end{equation} 
Für jede weitere gelöste Übungsaufgabe eines Schulkindes $j$ aus der Klasse 3 steigt also die erwartete Punktzahl im Mittel um $\Sexpr{beta13}$ Punkte an. Betrachten wir nun die Klasse 1 aus unserem Beispiel, schätzt unser Modell eine negative zufällige Abweichung $U_{11} = \Sexpr{u11}$ von der mittleren Steigung. Wird dieser Wert wieder in die Gleichung für $\beta_{1j}$ aus \eqref{eq:random_intercept_slope_model} eingesetzt, erhalten wir einen klassenspezifische Steigung von $\beta_{11} = \Sexpr{beta11}$. Diese Steigung ist nun kleiner als die mittlere Steigung aller Klassen $\gamma_{10} = \Sexpr{gamma10}$. Folglich nimmt die erreichte Punktzahl bei einer weiteren gelösten Übungsaufgabe eines Schulkindes $j$ aus der Klasse 1 im Mittel nur um $\Sexpr{beta11}$ zu. 

In unserem Beispiel ist es also so, dass je höher der klassenspezifische Achsenabschnitt ist, desto höher ist auch die klassenspezifische Steigung Steigung. Man spricht hier auch von einer positiven Korrelation zwischen Achsenabschnitt und Steigung. Diese beiden Koeffizienten müssen aber nicht zwingend positive miteinander korreliert sein. Es gibt auch die Möglichkeit, dass diese Koeffizienten negativ korreliert oder sogar unkorreliert sind. In Abbildung \ref{fig:corr_s_i} kann man betrachten, wie die weiteren Korrelationen von Achsenabschnitt und Steigung sich auswirken. Bei einer negativen Korrelation nimmt die Steigung mit der Höhe des Achsenabschnittes ab. Sind die beiden Koeffizienten unkorreliert, bildet sich kein offensichtliches Muster zwischen der Höhe des Achsenabschnittes und der Steigung.

\begin{figure}[ht!]
\centering
\includegraphics[width = \textwidth]{corr_s_i}
\caption{Darstellung einer negativen und nicht vorhandenen Korrelationen zwischen Achsenabschnitt und Steigung}
\label{fig:corr_s_i}
\end{figure}

In Abschnitt \ref{section:random_intercept_model} wurden die Residuenplots eines linearen Modells und eines \textit{Random Intercept} Modells verglichen. Dabei ist aufgefallen, dass das \textit{Random Intercept} Modell zwar kleinere Residuen aufwies, diese aber an den Endpunkten nicht um den Nullpunkt normalverteilt waren. Vergleicht man nun den Residuenplot aus Abbildung \ref{fig:resid_rism} mit den anderen aus der Abbildung \ref{fig:resid_lm_rim}, hat sich die Lage bezüglich der Verteilung der Residuen an den Endpunkten deutlich verbessert im \textit{Random Intercept and Slope} Modell.
 
\begin{figure}[ht!]
\centering
\captionsetup{width=8cm}
\includegraphics[width = 8cm, height = 8cm]{residuen_rism}
\caption{Residuenplot des \textit{Random Intercept and Slope} Modells}
\label{fig:resid_rism}
\end{figure}

\subsubsection{\textit{Intercept} und \textit{Slope} Variabilität} \label{section:variability}
Wie bei linearen Regressionsmodellen wird auch bei hierarchsichen linearen Regressionsmodellen versucht die Variabilität einer bestimmten Abhängigen Variablen zu erklären. Diese unerklärte Variabilität hängt in hierarchischen linearen Modellen nicht nur von der Varianz des Residuums $\epsilon_{ij}$ ab, sondern auch von der Varianz der zufälligen Abweichung des Achsenabschnittes $U_{0j}$ und der Steigung $U_{1j}$ \citep{SnijdersTomA.B2012Ma:a}. Um nun unerklärte Variabilität in hierarchischen Modellen zu beschreiben, können alle dieser Komponenten angegangen werden. Um die Varianz des Residuums zu verringern können, wie bei der normalen linearen Regression, weitere Level-1 Variablen in das Modell aufgenommen werden. Um die Varianz der beide zufälligen Abweichungen zu verringern wird es etwas anspruchsvoller, da diese beiden Varianzen nicht durch Unterschieden innerhalb der Gruppen sondern zwischen den Gruppen entstehen. Folglich können diese Varianzen nicht durch das Hinzufügen von Level-1 Variablen reduziert werden, sondern erfordern das Hinzufügen von Level-2 Variablen. Snijders und Bosker \citeyearpar{SnijdersTomA.B2012Ma:a} erweitern hierfür die beiden Gleichungen für die Regressionskoeffizienten $\beta_{0j}$ und $\beta_{1j}$:
\begin{equation} \label{eq:variance}
\begin{split}	
 \text{Level 1:}  \qquad y_{ji} & = \beta_{0j} + \beta_{1}x_{ij} + \epsilon_{ij}\\
 \text{Level 2:} \qquad \beta_{0j} & = \gamma_{00} + \gamma_{01}z_{j} + U_{0j}\\
 \beta_{1j} & = \gamma_{10} + \gamma_{11}z_{j} + U_{1j}
\end{split}	
\end{equation}
Dabei ist $z_{j}$ eine Level-2 Variable, die sich zwischen den Gruppen unterscheidet. Auf unser Beispiel bezogen, könnte die Variable $z_{j}$ die Anzahl Fenster im Klassenzimmer sein. Durch das Hinzufügen dieser Level-2 Variablen werden die Regressionskoeffizienten selbst zu einer Abhängigen Variablen eines Regressionmodells. Setzt man nun die beiden Koeffizienten in die Level-1 Gleichung ein erhält man wieder die flache Notation des Modells:
\begin{equation} \label{eq:flat_variance}
\begin{split}	
y_{ji} & = \beta_{0j} + \beta_{1}x_{ij} + \epsilon_{ij}\\
& = \gamma_{00} + \gamma_{01}z_{j} + U_{0j} + (\gamma_{10} + \gamma_{11}z_{j} + U_{1j})x_{ij} + \epsilon_{ij}\\
& = \gamma_{00} + \gamma_{01}z_{j} + U_{0j} + \gamma_{10}x_{ij} + \gamma_{11}z_{j}x_{ij} + U_{1j}x_{ij} + \epsilon_{ij}\\
& = \gamma_{00} + \gamma_{01}z_{j} + \gamma_{10}x_{ij} + \gamma_{11}z_{j}x_{ij} + U_{0j} + U_{1j}x_{ij} + \epsilon_{ij}\\
\end{split}	
\end{equation} 
Auch wenn es in der hierarchischen Notation einfacher ist zu erkennen, welche Varianz genau durch die Hinzunahme dieser Level-2 Variable verringert wird, erkennt man in der flachen Notation einen weiteren wichtigen Zusammenhang. Der Term $\gamma_{11}z_{j}x_{ij}$ beschreibt eine besondere Interaktion zwischen einer Level-1 und einer Level-2 Variable und wird, wie bereits in der Einleitung kurz erwähnt, als \textit{Cross-Level} Interaktion bezeichnet. Da diese \textit{Cross-Level} Interaktion durch das Hinzufügen einer Level-2 Variable als Prädiktor in der Gleichung des Steigungskoeffizienten entsteht, ist diese Interaktion vor allem wichtig, um unerklärte Varianz in der Steigung zu erklären. In unserem Beispiel würde diese \textit{Cross-Level} Interaktion also durch die Interaktion zwischen der Anzahl gelösten Übungsaufgaben und der Anzahl Fenster im Klassenzimmer beschreiben werden.

In den letzten Abschnitten wurden zwei verschiedene hierarchische lineare Modelle besprochen und das Prinzip ihrer Anwendung etwas näher gebracht. Es ist dabei zu berücksichtigen, dass hier nur die Grundlagen zu den hierarchischen linearen Modellen behandelt wurden. Für eine weitere Vertiefung dieses Themas wird auf die gängige Literatur zur Multilevel Analyse verwiesen \citep{andrew_data, raudenbush2002hierarchical, SnijdersTomA.B2012Ma:a, twisk_2006}. Im anschliessenden Abschnitt geht es nun darum, wie man solche Modelle in R berechnet und Multilevel Analysen durchführt.

\subsection{Anwendung von Multilevel Analyse in R} \label{section:ml_in_R}
Das Konzept von hierarchischen linearen Modellen wurde in den letzten Abschnitten ausführlich besprochen. In den nächsten Abschnitten wird vor allem die Anwendung dieser Modelle behandelt. Dabei wird der Fokus auf die Programmiersprache R gelegt und dessen Zusatzpaket \texttt{lme4} \citep{batesetal2015lme4}, das neben weiteren Paketen die Analyse mittels HLMs ermöglicht. Dabei wird davon ausgegangen, dass die Grundlagen dieser Programmiersprache verstanden wurden. Zuerst werden allgemeine Informationen und die Syntax von \texttt{lme4} besprochen. Anschliessend wird anhand unseres Beispiels ein erstes Modell geschätzt und dessen \texttt{summary()}-Output interpretiert. Dabei werden noch weitere Möglichkeiten besprochen, wie man Ergebnisse eines Geschätzten Modells präsentieren kann. Nachdem die Syntax und Interpretation des Modells besprochen wurden, wird Schritt für Schritt eine Multilevel Analyse unseres Beispiels durchgeführt. Hierbei wird aufgezeigt, wie HLMs aufgebaut und miteinander verglichen werden, um das geeignetste Modell zu identifizieren. Am Ende dieses Abschnittes werden Effektsterkemasse besprochen, die bei der Auswertung und Berichterstattung von HLMs wichtig sind.  

\subsubsection{Informationen und Syntax von \texttt{lme4}}
Mit dem Paket \texttt{lme4} lassen sich verschiedenste Formen von hierarchischen Modellen schätzen und analysieren. Dabei werden wir uns hier hauptsächlich auf die Funktion \texttt{lmer()} beschränken. Diese Funktion wird verwendet, um hierarchische lineare Modelle zu schätzen und dessen Syntax ist relativ ähnlich mit der Syntax des Befehls für die Berechnung normaler linearer Modelle \texttt{lm()}. Sie ist wie folgt aufgebaut:

<<echo = TRUE, error=FALSE, warning=FALSE, message=FALSE, eval = FALSE>>=
lmer(formula, data, REML)
@

Dabei wird in \texttt{formula} die gewünschte Formel des Modells eingegeben, bei \texttt{data} wird der Datensatz festgelegt anhand das Modell geschätzt werden soll und bei \texttt{REML} wird durch einen logischen Operator (\textit{TRUE} oder \textit{FALSE}) eingestellt, ob das Modell mit \textit{Restricted Maximum Likelihood} (REML) oder mit \textit{Maximum Likelihood} (ML) geschätzt werden soll. In unserem Fall ist diese Einstellung vor allem beim Vergleich von Modellen wichtig. Bei Modellen die mit REML geschätzt wurden, können nur die zufälligen Effekte miteinander verglichen werden. Wenn man also feste als auch zufällige Effekte vergleichen möchte, sollte man Modelle mit ML schätzen \citep{PEUGH201085}. 

<<echo = TRUE, error=FALSE, warning=FALSE, message=FALSE, eval = FALSE>>=
lmer(Abhängige Variable ~ Feste Effekte + (Zufällige Effekte | Gruppe), ... )
@

Bis zum Term innerhalb der Klammer ist die Syntax von \texttt{lmer()} genau die gleiche wie bei \texttt{lm()}. Dabei wird auf zuerst die zu erklärende Variable aufgeführt und anschliessend alle Variablen, die als feste Effekte in das Modell aufgenommen werden sollen. Innerhalb der Klammern können nun die zufälligen Effekte und die variierende Gruppe festgelegt werden. Dabei kann innerhalb der Klammern eingestellt werden, ob der Achsenabschnitt und die Steigung korrelieren sollten oder nicht. In Tabelle \ref{tab:lmersyntax} findet man einen Überblick über die möglichen Interaktionen, die man innerhalb der Klammer festlegen kann und die für uns relevant sind\footnote{Weitere Funktionen und eine ausführliche Beschreibung des Paketes \texttt{lme4} können in Bates et al. \citeyearpar{batesetal2015lme4} nachgeschlagen werden.}.
\begin{table}[ht] 
\centering
\begin{threeparttable}
\caption{Mögliche Syntax für \texttt{lmer()} nach Bates et al. \citeyearpar{batesetal2015lme4}}
\begin{tabular}{ll}
 	\toprule
	Formel & Bedeutung\\ 
  	\midrule
	(1 $|$ Gruppe)	& Zufälliger Achsenabschnitt \\
	(x $|$ Gruppe) & Korrelierter Achsenabschnitt und Steigung \\
	(x $||$ Gruppe) & Unkorrelierter Achsenabschnitt und Steigung\\
  	\bottomrule
\end{tabular}
\label{tab:lmersyntax}
\end{threeparttable}
\end{table}

\subsubsection{Interpretation eines Outputs} \label{section:interpretation_output}
Wir haben nun den groben Aufbau von \texttt{lmer()} besprochen und schätzen nun ein erstes Modell. Dafür muss zuerst das Paket \texttt{lme4} und unser Beispieldatensatz geladen werden.

\singlespacing
<<echo = TRUE, error=FALSE, warning=FALSE, message=FALSE, eval = TRUE>>=
library(lme4)
beispiel_data <- readRDS(file = "dataset_theory")
@
\setstretch{1.5}

Anschliessend wird ein Modell mit der Anzahl gelösten Übungen als fester Effekt und mit variierenden Achsenabschnitten und Steigungen geschätzt und mittels \texttt{summary()} übersichtlich ausgegeben.

\singlespacing
<<echo = TRUE, error=FALSE, warning=FALSE, message=FALSE, eval = TRUE, tidy=TRUE>>=
beispiel_model <- lmer(punktzahl ~ uebung + (uebung | klasse), data = beispiel_data, REML = FALSE)
summary(beispiel_model)
@
\setstretch{1.5}
<<echo = FALSE, error=FALSE, warning=FALSE, message=FALSE>>=
options(width=60)
options(digits = 2)
ml_data <- readRDS(file = "dataset_theory")
model <- lmer(punktzahl ~ uebung + (uebung|klasse), data = ml_data, REML = FALSE)

std_i <- attr(VarCorr(model)$klasse, "stddev")[1]
std_s <- attr(VarCorr(model)$klasse, "stddev")[2]

gamma00 <- fixef(model)[1]
gamma10 <- fixef(model)[2]
@
Dabei kann man im Output direkt die geschätzten Werte für die zufälligen und festen Effekte ablesen. Bei den zufälligen Effekten werden für den Achsenabschnitt als auch für die Steigung die geschätzte Varianzen, die Standardabweichungen, als auch die Korrelation dieser beiden angegeben. Ebenfalls werden direkt unterhalb der zufälligen Effekte aufgeführt wie gross die verwendete Stichprobe war und wie viele Gruppen für die Schätzung verwendet wurden. In unserem Fall waren das 150 Schulkinder, verteilt auf 5 Klassen. Der Abschnitt zu den festen Effekten ähnelt stark dem Output der Funktion \texttt{lm()} und lässt sich auch dementsprechend interpretieren. Es werden hier aber keine $p$-Werte angezeigt, da man sich in der Forschung noch uneinig darüber ist, wie genau die Anzahl der Freiheitsgrade geschätzt werden soll \citep{PEUGH201085,SnijdersTomA.B2012Ma:a}\footnote{Möchte man $p$-Werte anzeigen lassen, kann man das mit dem Paket \texttt{lmerTEST} \citep{lmertest}.}. Eine Interpretation des Achsenabschnittes unter Berücksichtigung der zufälligen Effekte würde dann wie folgt lauten: 
\begin{quote}
Die erwartete erreichte Punktzahl in der Mathematikprüfung ist $\Sexpr{gamma00} \pm 2 \cdot \Sexpr{std_i}$ Punkte, wenn keine einzige Übungsaufgabe gelöst wurde.
\end{quote}
Und für die Steigung:
\begin{quote}
Die erwartete Zunahme der Punktzahl beträgt $\Sexpr{gamma10} \pm 2 \cdot \Sexpr{std_s}$ pro gelöste Übungsaufgabe.
\end{quote}
Dabei ist \Sexpr{std_i} die Standardabweichung des Achsenabschnittes und \Sexpr{std_s} die Standardabweichung der Steigung. Bei der Interpretation ist es von Vorteil die Standardabweichung zu verwenden, da diese nicht wie die Varianz quadriert ist und somit der Masseinheit (Punktzahl) entspricht. 

\subsubsection{Berechnung der Intraklassen Korrelation in R} \label{section:icc_r}
Wir gelangen nun zur Analyse unseres Beispieldatensatzes. Bevor wir mit der Analyse starten können ist es wichtig, dass wir das Level unserer Forschungsfrage klar definieren. In unserem Fall möchten wir herausfinden, wie genau sich die Prüfungsleistung von Schulkindern mit der Anzahl gelöster Übungsaufgaben unter Berücksichtigung der Klassenzugehörigkeit verändert. Das bedeutet, dass sich unsere abhängige Variable auf Level-1 befindet. Ebenfalls sollte berücksichtigt werden, dass es zu Interaktionen zwischen Level-1 und Level-2 variablen kommen kann. Da wir sehr wahrscheinlich nicht nur feste Effekte sondern auch zufällige Effekte miteinander Vergleichen möchten, müssen wir zudem die Modelle mit ML schätzen \citep{PEUGH201085}. 

Als Erstes sollte immer geprüft werden, ob eine Multilevel Analyse überhaupt nötig ist. Dies geschieht zum einen durch die Berechnung der Intraklassen Korrelation und der Überprüfung, ob überhaupt mittlere Unterschiede zwischen den Klassen bestehen. Wie bereits im Abschnitt \ref{section:icc} besprochen, lässt sich die IKK aus den Varianzen des leeren Modells berechnen, das hier noch einmal kurz aufgeführt ist:
\begin{equation}
\begin{split}	
 \text{Level 1:}  \qquad y_{ji} & = \beta_{0j} + \epsilon_{ij}\\
 \text{Level 2:} \qquad \beta_{0j} & = \gamma_{00} + U_{0j}\\
\end{split}	
\end{equation} 
Dieses Modell wird wie folgt in R mittels der Funktion \texttt{lmer()} geschätzt:

\singlespacing
<<echo = TRUE, error=FALSE, warning=FALSE, message=FALSE, eval = TRUE, tidy=TRUE>>=
m_leer <- lmer(punktzahl ~ (1 | klasse), data = beispiel_data, REML = FALSE)

summary(m_leer)
@
\setstretch{1.5}

Aus dem Output können nun die Varianzen für den Achsenabschnitt und das Residuum abgelesen und in die Formel \eqref{eq:icc} eingesetzt werden. Daraus ergibt sich die bereits berechnete intraklassen Korrelation von $\rho_I = \Sexpr{icc}$. Folglich werden \Sexpr{icc_p}\% der Variabilität in der erreichten Punktzahl durch die Klassenzugehörigkeit erklärt. Um nun noch herauszufinden, ob diese Klassenunterschiede auch signifikant sind, kann eine Varianzanalyse durchgeführt werden \citep{SnijdersTomA.B2012Ma:a}. Dies geschieht indem man ein normales lineares Modell schätzt, das nur anhand der Klasse Leistungsunterschiede erklären möchte. Wie ebenfalls aus Abschnitt \ref{section:icc} bekannt, ergibt sich aus der Varianzanalyse einen hoch signifikanten $p$-Wert. Es bestehen folglich mittlere Klassenunterschiede in der erreichten Punktzahl, die in der Analyse zu berücksichtigen sind. 

\singlespacing
<<echo = TRUE, error=FALSE, warning=FALSE, message=FALSE, eval = TRUE, tidy=TRUE>>=
m_linear <- lm(punktzahl ~ klasse, data = beispiel_data)

anova(m_linear)
@
\setstretch{1.5}

\subsubsection{Aufbau und Vergleich von Modellen}
Da nun die Frage geklärt ist, ob unser Datensatz eine Multilevel Analyse verlangt, können wir damit anfangen unser leeres Modell mit weitere Prädiktoren aufzubauen. In unserem Beispiel fügen wir die Anzahl gelöste Übungsaufgaben als festen Effekt dem Modell hinzu. Natürlich könnten hier noch weitere feste Effekte hinzugefügt werden, damit das Beispiel aber übersichtlich bleibt, ist das Modell hier auf einen festen Effekt beschränkt:
\begin{equation}
\begin{split}	
 \text{Level 1:}  \qquad y_{ji} & = \beta_{0j} + \beta_{1} \cdot \text{uebungen}_{ij} + \epsilon_{ij}\\
 \text{Level 2:} \qquad \beta_{0j} & = \gamma_{00} + U_{0j}\\
 \beta_{1} & = \gamma_{10}\\
\end{split}	
\end{equation} 
In der oberen Gleichung kann man erkennen, dass es sich hier um ein einfaches \textit{Random Intercept} Modell handelt, da bei $\beta_{1}$ keine zufällige Abweichung hinzugefügt wurde. Um nun ein \textit{Random Intercept} Modell in R zu schätzen wird der Funktion die Variable wie folgt hinzugefügt:

\singlespacing
<<echo = TRUE, error=FALSE, warning=FALSE, message=FALSE, eval = TRUE, tidy=FALSE>>=
m_intercept <- lmer(punktzahl ~ uebung + (1 | klasse), 
	data = beispiel_data, REML = FALSE)
@
\setstretch{1.5}

Dabei ist zu beachten, dass der Term innerhalb der Klammern der Vorgabe aus Tabelle \ref{tab:lmersyntax} entspricht, um ein \textit{Random Intercept} Modellzu schätzen. Möchte man nun zusätzlich ein \textit{Random Intercept and Slope} Modell schätzen wird entsprechend des Abschnittes \ref{section:random_intercept_slope_model} der Gleichung von $\beta_{1j}$ eine zufällige Abweichung von der mittleren Steigung hinzugefügt: 
\begin{equation} 
\begin{split}	
 \text{Level 1:}  \qquad y_{ji} & = \beta_{0j} + \beta_{1} \cdot \text{uebungen}_{ij} + \epsilon_{ij}\\
 \text{Level 2:} \qquad \beta_{0j} & = \gamma_{00} + U_{0j}\\
 \beta_{j1} & = \gamma_{10 }+ U_{1j}\\
\end{split}	
\end{equation} 
Dieser zufällige Effekt wird nun auch in der Formel in R gemäss Tabelle \ref{tab:lmersyntax} hinzugefügt:

\singlespacing
<<echo = TRUE, error=FALSE, warning=FALSE, message=FALSE, eval = TRUE, tidy=FALSE>>=
m_uncorr <- lmer(punktzahl ~ uebung + (uebung || klasse), 
	data = beispiel_data, REML = FALSE)
	
m_corr <- lmer(punktzahl ~ uebung + (uebung | klasse), 
	data = beispiel_data, REML = FALSE)
@
\setstretch{1.5}

Wir haben hier gleich zwei Varianten eines \textit{Random Intercept and Slope} Modell geschätzt. Zum einen eines bei dem der Achsenabschnitt und die Steigung unkorreliert sind und zum anderen ein Modell, bei dem beide Koeffizienten miteinander korrelieren. Um das Modell zu identifizieren, das am meisten erklärte Varianz aufweist, kann man wie beim Vergleich von normalen linearen Modellen mit dem Befehl \texttt{anova()} die Modelle vergleichen. Dabei wird hier nicht wie für normale lineare Modelle üblich ein \textit{F} Test sondern ein \textit{Likelihood Ration Test} verwendet \citep{PEUGH201085,SnijdersTomA.B2012Ma:a}. 

Wenn Modelle mit einer \textit{Maximum Likelihood} Methode geschätzt werden, wird immer eine \textit{Likelihood} des Modells angegeben, die wiederum in einen sogenannten \textit{Deviance} Wert umgewandelt werden kann. Betrachtet man den Output aus Abschnitt \ref{section:interpretation_output}, findet man den \textit{Deviance} Wert in der oberen Hälfte des Outputs. Dieser \textit{Deviance} Wert gibt an, wie genau das Modell zu den Daten passt und kann folglich verwendet Werden, um Modelle zu vergleichen \citep{SnijdersTomA.B2012Ma:a}. Die Differenz des \textit{Deviance} Werts zweier Modelle kann als Testwert einer $\chi^2$-Verteilung verwendet werden. 

Betrachtet man nun den folgenden Outputs wird klar, dass ein \textit{Random Intercept and Slope} Modell mit unkorrelierten Achsenabschnitten und Steigungen am besten zu unseren Daten passt. 

\singlespacing
<<echo = TRUE, error=FALSE, warning=FALSE, message=FALSE, eval = TRUE, tidy=TRUE>>=
anova(m_intercept, m_corr, m_uncorr, method = "LRT")
@
\setstretch{1.5}

Bis jetzt haben wir uns nur mit Level-1 Variablen beschäftigt. Möchten wir dem Modell die Anzahl Fenster im Klassenzimmer als Level-2 Variable hinzufügen, kann man diese Variable mit \textit{Cross-Level} Interaktion oder ohne hinzufügen. Ebenfalls ist zu beachten, dass Level-2 Variablen in einem hierarchischen linearen Modell mit zwei Level nur mit festen Effekten hinzugefügt werden können. Da es in einem zwei Level Modell nicht noch ein drittes höheres Level gibt, von dem eine Level-2 Variable abhängen könnte. Mathematisch würde das Hinzufügen einer Level-2 Variable ohne \textit{Cross-Level} Interaktion wie folgt aussehen:
\begin{equation} 
\begin{split}	
 \text{Level 1:}  \qquad y_{ji} & = \beta_{0j} + \beta_{1} \cdot \text{uebungen}_{ij} + \epsilon_{ij}\\
 \text{Level 2:} \qquad \beta_{0j} & = \gamma_{00} + \gamma_{01} \cdot \text{fenster}_{j} + U_{0j}\\
 \beta_{j1} & = \gamma_{1j} + U_{1j}\\
\end{split}	
\end{equation} 
In Abschnitt \ref{section:variability} wurde allerdings mathematisch gezeigt, dass \textit{Cross-Level} Interaktionen wichtig für die Erklärung von Steigungsvarianz sind. In der folgenden Gleichung wurde die Variable dementsprechend mit einer \textit{Cross-Level} Interaktion hinzugefügt:
\begin{equation} 
\begin{split}	
 \text{Level 1:}  \qquad y_{ji} & = \beta_{0j} + \beta_{1} \cdot \text{uebungen}_{ij} + \epsilon_{ij}\\
 \text{Level 2:} \qquad \beta_{0j} & = \gamma_{00} + \gamma_{01} \cdot \text{fenster}_{j} + U_{0j}\\
 \beta_{j1} & = \gamma_{1j} + \gamma_{11} \cdot \text{fenster}_{j} + U_{1j}\\
\end{split}	
\end{equation} 
In R ist das Hinzufügen von Level-2 Variablen relativ einfach, da eine Level-2 Variable in unserem Fall nur als fester Effekt hinzugefügt werden kann, wird sie einfach in die Gleichung vor dem Term in der Klammer eingefügt. Folgend wurden die beiden Modelle geschätzt, eines ohne und eines mit \textit{Cross-Level} Interaktion.

\singlespacing
<<echo = TRUE, error=FALSE, warning=FALSE, message=FALSE, eval = TRUE, tidy=FALSE>>=
m_lvl2 <- lmer(punktzahl ~ uebung + fenster + (uebung || klasse), 
	data = beispiel_data, REML = FALSE)
	
m_cross <- lmer(punktzahl ~ uebung * fenster + (uebung || klasse), 
	data = beispiel_data, REML = FALSE)
@
\setstretch{1.5}

Diese Modelle werden nun wieder mit unserem unkorrelierten \textit{Random Intercept and Slope} Modell verglichen, um herauszufinden, ob das Hinzufügen einer Level-2 Variable das Modell verbessert hat:

\singlespacing
<<echo = TRUE, error=FALSE, warning=FALSE, message=FALSE, eval = TRUE, tidy=TRUE>>=
anova(m_uncorr, m_lvl2, m_cross, method = "LRT")
@
\setstretch{1.5}

Wie man erkennen kann, ist keines der neuen Modelle besser als das unkorrelierte \textit{Random Intercept and Slope} Modell. Folglich wird für die weiteren Abschnitte dieses Modell verwendet, da es anscheinend am meisten Varianz aufklärt.

\subsubsection{Auswertung von Modellen}
Bis jetzt wurden nur Modelle miteinander verglichen und herausgefunden, dass ein unkorreliertes \textit{Random Intercept and Slope} Modell am meisten Varianz aufklärt. In der normalen linearen Regression gibt es viele verschieden Effektstärkemasse, die genutzt werden können, um Aussagen über Modelle zu treffen. Beispielsweise gibt es das Bestimmtheitsmass $R^2$ oder das Cohen's $d$, die den meisten ein Begriff sind. In den hierarchischen linearen Modell ist das Berechnen von Effektstärkemassen etwas komplizierter und es herrscht aktuell keinen Konsens darüber, was für Effektstärkemasse genau verwendet werden sollen \citep{PEUGH201085,SnijdersTomA.B2012Ma:a}. 

Dabei werden Effektstärkemasse von hierarchischen linearen Modellen in globale und lokale Effektstärkemasse getrennt \citep{PEUGH201085}. Bei den globalen Effektstärkemasse gibt es mehrere Formen von Bestimmtheitsmassen $R^2$, von denen hier nur dasjenige von Snijders und Bosker \citeyearpar{SnijdersTomA.B2012Ma:a} behandelt wird. Die beiden Autoren sprechen davon, dass bei hierarchischen linearen Modellen auf mehreren Levels die proportional erklärte Varianz berechnet werden kann. Ausgehend von unserem Beispiel mit zwei Level kann man proportional erklärte Varianz auf Stufe des Individuums und auf Stufe der Gruppe berechnen. Snijders und Bosker \citeyearpar{SnijdersTomA.B2012Ma:a} geben an, dass vor allem die proportionale erklärte Varianz des Individuums von praktischer Relevanz ist und wird durch $R_{1}^2$ gekennzeichnet. Die Berechnung von $R_{1}^2$ erfolgt dann mit:
\begin{equation} 
\begin{split}	
 R_{1}^2 & = 1 - \dfrac{\text{Gesamtvarianz des Modells mit Prädiktoren}}{\text{Gesamtvarianz des leeren Modells}} \\
 & \\
 & = 1 - \dfrac{\sigma^2 + \tau_{0}^2}{\sigma_{leer}^2 + \tau_{0leer}^2}
\end{split}	
\end{equation}
Dabei ist $\sigma^2$ die jeweilige Varianz des Residuums und $\tau_{0}^2$ die Varianz des Achsenabschnittes des jeweiligen Modelles. Da in der Berechnung von $R_{1}^2$ die Varianz der Steigung nicht berücksichtigt wird, kann dieses Effektstärkemass nur für \textit{Random Intercept} Modelle berechnet werden. Snijders und Bosker \citeyearpar{SnijdersTomA.B2012Ma:a} empfehlen für \textit{Random Intercept and Slope} Modelle, dass diese mit den selben festen Effekten als \textit{Random Intercept} Modell geschätzt werden, um anschliessend das $R_{1}^2$ zu berechnen. Diese Methode ist viel einfacher als andere gängige Methoden zur Berechnung von $R_{1}^2$ für \textit{Random Intercept and Slope} Modelle und sollte normalerweise zu $R_{1}^2$ Werte führen, die sehr nahe an den Werten für ein \textit{Random Intercept and Slope} Modell liegen.

Möchten wir nun $R_{1}^2$ für unser Beispiel berechnen müssen wir zuerst unser Modell als \textit{Random Intercept} Modell schätzten.

\singlespacing
<<echo = TRUE, error=FALSE, warning=FALSE, message=FALSE, eval = TRUE, tidy=FALSE>>=
m_i <- lmer(punktzahl ~ uebung + (1 | klasse), 
	data = beispiel_data, REML = FALSE)
	
summary(m_i)
@

<<echo = FALSE, error=FALSE, warning=FALSE, message=FALSE, eval = TRUE, tidy=FALSE>>=
m_leer <- lmer(punktzahl ~ (1 | klasse), 
	data = beispiel_data, REML = FALSE)

tau1 <- VarCorr(m_i)$klasse[1,1]
sigma1 <- sigma(m_i)^2

tau0 <- VarCorr(m_leer)$klasse[1,1]
sigma0 <- sigma(m_leer)^2

rsquare <- 1 - (tau1 + sigma1) / (tau0 + sigma0)
rsquare_p <- round(rsquare * 100, digits = 0)
@
\setstretch{1.5}

Im Output aus Abschnitt \ref{section:icc_r} können die Varianzen des leeren Modells abgelesen werden und mit den Varianzen aus dem Outupt für das \textit{Random Intercept} Modells in die Formel eingesetzt werden:
\begin{equation} 
\begin{split}	
 R_{1}^2 & = 1 - \dfrac{\Sexpr{sigma1} + \Sexpr{tau1}}{\Sexpr{sigma0} + \Sexpr{tau0}} = \Sexpr{rsquare}
\end{split}	
\end{equation}
Folglich kann man nun die Aussage treffen, dass unser Modell \Sexpr{rsquare_p}\% der Varianz in der erreichten Punktzahl von Schulkindern erklärt.

Es gibt aber auch Situationen in denen man genau wissen möchte, wie viel Varianz durch die Hinzunahme eines bestimmten Prädiktors im Modell erklärt wird. Dies kann man mit der proportionalen Reduktion der Varianz (PRV) erklären, die als eines der lokale Effektstärkemasse von hierarchischen linearen Modellen gilt \citep{PEUGH201085, woltman2012introduction}. Die Berechnung der proportionalen Reduktion der Varianz wird für jede einzelne Varianz des Modells durchgeführt. Das bedeutet, dass die PRV für die Varianz des Residuums, des Achsenabschnittes und für die der Steigung berechnet werden kann. Die Formel zur Berechnung der PRV bleibt aber für alle Fälle die gleiche:
\begin{equation} \label{eq:prv}
\begin{split}	
 PRV = \dfrac{Var_{0} - Var_{1}}{Var_{0}}
\end{split}	
\end{equation}
Dabei ist $Var_{0}$ die Varianz des Modells, das den gewünschten Prädiktor nicht enthält und $Var_{1}$ des Modells, das den Prädiktor enthält. Gehen wir nun ganz an den Anfang unserer Analyse zurück und überprüfen, wie viel Varianz im Vergleich zum leeren Modell durch die Hinzunahme der Anzahl gelösten Übungsaufgaben als Prädiktor reduziert wird. Dazu wurden folgend die Varianzkomponenten des leeren Modells und des ersten \textit{Random Intercept} Modells ausgegeben. 

\singlespacing
<<echo = TRUE, error=FALSE, warning=FALSE, message=FALSE, eval = TRUE, tidy=TRUE>>=
m_leer <- lmer(punktzahl ~ (1 | klasse), 
	data = beispiel_data, REML = FALSE)
print(VarCorr(m_leer), comp = "Variance")	
	
m_uebung <- lmer(punktzahl ~ uebung + (1 | klasse), 
	data = beispiel_data, REML = FALSE)
print(VarCorr(m_uebung), comp = "Variance")
@

<<echo = FALSE, error=FALSE, warning=FALSE, message=FALSE, eval = TRUE, tidy=FALSE>>=
sigma0 <- sigma(m_leer)^2
sigma1 <- sigma(m_uebung)^2
prv_r <- (sigma0 - sigma1) / sigma0
prv_r_p <- round(prv_r * 100, digits = 0)
@
\setstretch{1.5}

Die Varianz der Residuen des leeren Modells beträgt $\sigma_{0}^2 = \Sexpr{sigma0}$ und die Varianz der Residuen des \textit{Random Intercept} Modells $\sigma_{1}^2 = \Sexpr{sigma1}$. Fügen wir diese beiden Werte in die Formel \eqref{eq:prv} ein erhalten wir die proportionale Reduktion der Varianz des Residuums:
\begin{equation} 
\begin{split}	
 PRV_{R} = \dfrac{\Sexpr{sigma0} - \Sexpr{sigma1}}{\Sexpr{sigma0}} = \Sexpr{prv_r}
\end{split}	
\end{equation}
Daraus kann nun geschlossen werden, dass durch die Hinzunahme der Anzahl gelösten Übungsaufgaben als Prädiktor für die erreichte Punktzahl in der Mathematikprüfung eine Reduktion der Residualvarianz von \Sexpr{prv_r_p}\% erreicht wird. Da wir in unserem Modell nur eine Level-1 Variable als festen Effekt hinzugefügt haben, kann keine weitere PRV für den Achsenabschnitt und der Steigung berechnet werden. Möchte man die Varianzen dieser beiden Koeffiziente reduzieren, müssen wie bereits in Abschnitt \ref{section:variability} besprochen Level-2 Variablen in das Modell aufgenommen werden. Erst dann kann auch die proportionale Reduktion der Varianz mit der oberen Formel berechnet werden.

Im letzten Abschnitt wurde anhand eines einfachen Beispiels aufgezeigt, wie man eine exemplarische Multilevel Analyse in R durchführt. Das Ziel dieses Abschnittes war es in erster Linie zu zeigen, wie mit dem Paket \texttt{lme4} arbeitet und welche Möglichkeiten es gibt, um hierarchische Daten in R zu analysieren.

\section{Simulationsstudie zur Multilevel Analyse}
Der Einfluss von hierarchischen Datenstrukturen auf die Analyse wurden konzeptionell in den letzten Abschnitten diskutiert und vorgestellt. Im folgenden Abschnitt geht es nun, um die wissenschaftliche Replikation und Überprüfung dieses Einflusses. Dabei wird vor allem der Fokus auf die Unterschiede zwischen der Analyse mittels normaler linearer Regression und hierarchischer linearer Regression legen. Um diese beide Methoden zu vergleichen, wird eine Simulationsstudie durchgeführt.

Anschliessend an die Simulationsstudie wird eine Shiny App \citep{shiny} vorgestellt, die im laufe dieser Arbeit programmiert wurde und mit der es Nutzern möglich sein wird, zum einen das Konzept der Multilevel Analyse zu verstehen und zum anderen die Simulationsstudie aus dieser Arbeit selbst durchzuführen.

\subsection{Herleitung der Forschungsfrage}
In der Einleitung wurde bereits erwähnt, dass in der psychologischen Forschung hierarchische Datenstrukturen keine Seltenheit sind und es wurden einige Beispiele für solche hierarchischen Daten genannt \citep{raudenbush2002hierarchical,SnijdersTomA.B2012Ma:a,woltman2012introduction}. Allerdings ist es oft so, dass sich Forschende dieser Datenstruktur oder den Möglichkeiten von hierarchischen linearen Modellen nicht bewusst sind \citep{mcneish2014analyzing}. Dies kann dazu führen, dass diese hierarchischen Daten mittels normalen linearen Modellen anstelle von hierarchischen linearen Modellen analysiert wird. Das muss aber nicht zwingend ein Problem darstellen, da in einigen Studien gezeigt werden konnte, dass die Schätzung der Regressionskoeffizienten beider Analysemethoden auch bei hohem Einfluss der Klassenzugehörigkeit relativ genau ist \citep{mcneish2014analyzing, mundfrom2002monte}. Das bedeutet, dass die Schätzung des Effekts einer Intervention oder des Achsenabschnitts bei beiden Methoden relativ nahe am Populationsmittelwert sind. 

Allerdings ist eine genaue Schätzung der Regressionskoeffizienten nicht ausreichend, um zu bestimmen, ob der Effekt einer Intervention auch signifikant ist. Um das zu überprüfen wird üblicherweise ein \textit{t} Test durchgeführt \citep{SnijdersTomA.B2012Ma:a}. Die Prüfgrösse des \textit{t} Tests wird über das Verhältnis zwischen des geschätzten Regressionskoeffizienten und dessen Standardfehlers bestimmt. Wird beispielsweise ein Standardfehler zu klein geschätzt, steigt die Prüfgrösse an und die Rate in der die Nullhypothese abgelehnt wird, nimmt zu. Wird der Standardfehler zu gross geschätzt, verkleinert sich die Prüfgrösse und die Rate in der die Alternativhypothese abgelehnt wird, nimmt zu. Folglich führt eine Unterschätzung des Standardfehlers zu einer erhöhten Fehler Typ 1 Rate und eine Überschätzung zu einer erhöhten Fehler Typ 2 Rate und somit zu einer geringeren Power \citep{SnijdersTomA.B2012Ma:a}. Unter Power wird die Wahrscheinlichkeit verstanden, einen Effekt zu finden, wenn dieser auch effektiv in der Population vorhanden ist \citep{scherbaumferreter2009powersample}. Daher ist eine genau Schätzung des Standardfehlers umso wichtiger, da dieser massgeblich zur Testung des Effekts beiträgt. Da der Standardfehler in einem direkten Zusammenhang mit der Stichprobengrösse steht, ist die Wahl der Stichprobengrösse ein entscheidender Faktor \citep{mcneish2014analyzing, SnijdersTomA.B2012Ma:a}. Da bei hierarchischen Daten Beobachtungen aus der selben Gruppe ähnlicher zueinander sind als zu anderen Beobachtungen, verkleinert sich die effektive Stichprobengrösse \citep{raudenbush2002hierarchical}. Werden beispielsweise aus 100 Schulklassen 10 Schulkinder ausgewählt, würde das zu einer effektiven Stichprobengrösse von 100 führen. Ein normales lineares Modell würde in diesem Fall aber mit einer Stichprobengrösse von 1000 arbeiten, wohingegen ein hierarchisches lineares Modell mit der effektiven Stichprobengrösse von 100 arbeitet. Folglich können diese beiden Methoden zu unterschiedlichen Standardfehlern und dementsprechend auch zu unterschiedlichen Prüfgrössen für den \textit{t} Test gelangen. 

Neben der Prüfgrösse ist auch die Anazahl an Freiheitsgrade relevant, um die Signifikanz eines Effekts mittels \textit{t} Test zu überprüfen. Während bei normalen linearen Modellen die Anzahl Freiheitsgrade durch $N - p - 1$ bestimmt wird, wobei $N$ die Stichprobengrösse und $p$ die Anzahl Parameter im Modell sind, ist die Berechnung der Freiheitsgrade bei hierarchischen linearen Modellen nicht eindeutig geklärt und ein aktueller Forschungsgegenstand \citep{mcneish2014analyzing,raudenbush2002hierarchical,SnijdersTomA.B2012Ma:a}.

Aufgrund dieser Gegebenheiten ist es also wichtig, dass die verwendete Analysemethode der Struktur des Datensatzes gerecht wird, um ungenaue Schätzungen des Standardfehlers zu vermeiden. McNeish \citeyearpar{mcneish2014analyzing} konnte in seiner Studie zeigen, dass mit zunehmender Intraklassen Korrelation die Schätzung des Standardfehlers bei normalen linearen Modellen ungenauer wird. Diese Erkenntnis entspricht den Berechnungen, die aus dem Artikel von Moerbeek et al. \citeyearpar{MOERBEEK2003341} hervorgehen. In diesem Artikel differenzieren die Autoren zwischen zwei Studiendesigns, die in der Praxis häufig eingesetzt werden. Zum einen kann eine Intervention auf Level-1 durchgeführt werden und die zufällige Zuteilung zur Interventions- und Kontrollgruppe erfolgt auf Stufe der Schulkinder. Zum anderen kann man die Intervention auf Level-2 durchführen, wobei die Zuteilung auf Klassenstufe stattfindet. Moerbeek et al. \citeyearpar{MOERBEEK2003341} konnten in ihrem Artikel zeigen, dass der geschätzte Standardfehler einer Intervention mittels normaler lineare Regression je nach Studiendesign unter- oder überschätzt wird. 

(Hier: bei welchem design wird was erwartet)

Da Moerbeek et al. \citeyearpar{MOERBEEK2003341} nur einen einzigen Datensatz simuliert haben, sollten ihre Ergebnisse noch in einer Simulationsstudie überprüft werden. 

\subsection{Studiendesign}
In einer ersten Simulationsstudie wird folglich versucht, die Ergebnisse bezüglich der Effizienz der Schätzung der Regressionskoeffizienten von Mundform und Schults \citeyearpar{mundfrom2002monte} zu replizieren. Ebenfalls wird die Aussagen von Moerbeek et al. \citeyearpar{MOERBEEK2003341} überprüft, dass die Verwendung von normalen linearen Modellen zur Analyse von hierarchischen Daten je nach Studiendesign zu Über- oder Unterschätzung der Standardfehler führt. Zusätzlich wird die Intraklassen Korrelation variiert, um zu überprüfen, dass diese Über- oder Unterschätzung der Standardfehler bei Zunahme der Intraklassen Korrelation steigt \citep{mcneish2014analyzing}. Gemäss den Ergebnissen von McNeish \citeyearpar{mcneish2014analyzing} und Moerbeek et al. \citeyearpar{MOERBEEK2003341} wird erwartet, dass hierarchische lineare Modelle auch bei Zunahme der Intraklassen Korrelation zu keiner Über- oder Unterschätzung des Standardfehlers führen. 

In einer zweiten Simulationsstudie wird anhand realitätsnäheren simulierten Datensätzen versucht aufzuzeigen, wie sich die Power bezüglich einer Intervention zwischen den beiden Analysemethode bei variierender Interklassen Korrelation und gleichbleibender Stichprobengrösse unterscheidet. Dabei wird erwartet, dass durch die Anwendung von Multilevel Analyse bei einer Randomisierung der Intervention auf Level-1 eine grössere Power erreicht wird, als durch die Analyse mittels normalen linearen Modellen. Diese Erwartung begründet sich dadurch, da gemäss Moerbeek et al. \citeyearpar{MOERBEEK2003341} in dieser Situation die Analyse mit normalen linearen Modellen zu einer Überschätzung des Standardfehlers führt, dies führt wiederum zu einer erhöhten Fehler Typ 2 Rate und folglich zu einer tieferen Power. Bei der Randomisierung der Intervention auf Level-2 wird grundsätzlich eine tiefere Power erwartet, da in diesem Design der Effekt der Intervention nicht vom Effekt der Klassenzugehörigkeit getrennt werden kann \citep{donnerbirkettbuck1981randomization, hsieh1988samplesize}. Da nach Moerbeek et al. \citeyearpar{MOERBEEK2003341} eine Randomisierung auf Level-2 zu einer Unterschätzung des Standardfehlers führt, wird in diesem Fall erwartet, dass ein normales lineares Modell zu einer höheren aber immernoch tiefen Power führt.  

\subsection{Simulationsdesign}
Um diese Annahmen zu überprüfen werden in beiden Simulationsstudien Daten basierend auf den selben zwei Designs von Moerbeek et al. \citeyearpar{MOERBEEK2003341} generiert. Beim ersten Design handelt es sich um eine Intervention auf Stufe des Schulkindes und die Daten werden anhand der folgenden Gleichung generiert:
\begin{equation} 
\begin{split}
\text{Design 1:}\\	
 \text{Level 1:}  \qquad y_{ji} & = \beta_{0j} + \beta_{1}x_{ij} + \epsilon_{ij}\\
 \text{Level 2:} \qquad \beta_{0j} & = \gamma_{00} + U_{0j}\\
 \beta_{1} & = \gamma_{10}\\
 \end{split}	
\end{equation} 
Dabei ist $\epsilon_{ij}$ das Residuum des $i$-ten Schulkindes aus der $j$-ten Klasse. Die Variable $x_{ij}$ gibt an, ob sich das Schulkind $i$ aus der Klasse $j$ in der Interventions- oder Kontrollgruppe befindet. Der Koeffizient $\beta_{0j}$ beschreibt den Achsenabschnitt, der wiederum durch den Gesamtmittelwert $\gamma_{00}$ und der zufälligen Abweichung $U_{0j}$ der Klasse $j$ beschrieben wird. Der Koeffizient $\beta_{j1}$ wird nur durch die Gesamtsteigung $\gamma_{1j}$ beschrieben. Folglich wird keine klassenspezifische Abweichung der Steigung in der Studie simuliert.

Das zweite Design berücksichtigt Interventionen auf Stufe der Klassen. Dabei werden die Daten nach der folgenden Gleichung generiert:
\begin{equation} 
\begin{split}
 \text{Design 2:}\\
  \text{Level 1:}  \qquad y_{ji} & = \beta_{0j} + \epsilon_{ij}\\
 \text{Level 2:} \qquad \beta_{0j} & = \gamma_{00} + \gamma_{01}z_{j} + U_{0j}\\
\end{split}	
\end{equation} 
Wieder beschreibt $\epsilon_{ij}$ das Residuum des $i$-ten Schulkindes aus der $j$-ten Klasse. Der Achsenabschnitt $\beta_{0j}$ wird durch den Gesamtmittelwert $\gamma_{00}$, der Gesamtsteigung $\gamma_{01}$, der Variable $z_{j}$ und der klassenspezifischen zufälligen Abweichung $U_{0j}$ beschrieben. Die Variable $z_{j}$ gibt an, zu welcher Interventionsgruppe die $j$-te Klasse gehört. Da in diesem Design die Intervention auf Stufe der Klasse durchgeführt wird, handelt es sich bei der Intervention um eine Level-2 Variable und wird typischerweise mit $z_{j}$ und nicht mit $x_{j}$ bezeichnet. Es wird in beiden Designs angenommen, dass die zufälligen Effekte $\epsilon_{ij}$ und $U_{0j}$ voneinander unabhängig sind und einer Normalverteilung folgen. Ebenfalls wird angenommen, dass diese zufällige Effekte einen Mittelwert von Null und eine Varianz von $\sigma^{2}_{e}$, resp. $\tau^{2}_{0}$ aufweisen.

Gewisse Parameter werden in beiden Simulationsstudien nicht manipuliert. Für diese Parameter wurden die Werte von Moerbeek et al. \citeyearpar{MOERBEEK2003341} und McNeish \citeyearpar{mcneish2014analyzing} verwendet. Die Zuweisung zur Interventionsgruppe wurde für die Variablen $x_{ij}$ und $z_{j}$ durch die Werte -1 und 1 festgelegt. Dabei steht -1 für die Kontrollgruppe und 1 für die Interventionsgruppe. Der Gesamtmittelwert der Population wurde in beiden Designs auf $\gamma_{00}$ = 2.34 festgelegt. Die Gesamtsteigung der Population wurde ebenfalls in beiden Designs beider Simulationsstudien mit $\gamma_{10}$ = 0.12 resp. $\gamma_{01}$ = 0.12 festgehalten. Für die Varianz des Residuums wurde ein Wert von $\sigma^{2}_{e}$ = 1.72 verwendet. 

Neben den nicht manipulierten Parametern wurden die Intraklassen Korrelation und die Analysemethode variiert. Bei der IKK gab es insgesamt neun Bedingungen gab, die in drei Gruppen eingeteilt werden können. Die erste Gruppe entspricht einer IKK von 0.00 und beschreibt einen Datensatz bei der die Klassenzugehörigkeit keinen Einfluss hat. Die zweite Gruppe beinhaltet IKKs die typischerweise in der psychologischen Forschung angetroffen werden und reichen von 0.05 bis 0.25 mit einem Abstand von 0.05 zwischen den jeweiligen IKK Bedingungen \citep{SnijdersTomA.B2012Ma:a}. Die dritte Gruppe beinhaltet Extremwerte der IKK von 0.30, 0.40 und 0.50. Wie aus der Formel \eqref{eq:icc} zu entnehmen ist, wird die IKK alleine durch die Varianz des Residuums und durch die Varianz der zufälligen Abweichung bestimmt. Da durch das Studiendesign die Varianz des Residuums und die theoretische IKK vorgegeben ist, lässt sich durch Umformen der Formel \eqref{eq:icc} die Varianz der zufälligen Abweichung $\tau^{2}_{0}$ bestimmen. Anhand dieser Varianz wurden dann Datensätze generiert, die den theoretischen IKKs entsprechen. Für jede dieser Bedingung wurden in jedem Design jeweils 1000 Replikationen simuliert, das zu einer Gesamtanzahl von 18000 Replikationen führte. Dabei wurde jeder einzelne Replikation zum einen mit einer normalen linearen Regression und zum anderen mit einer hierarchischen linearen Regression analysiert. 

\subsection{Studie 1: Genauigkeit von Schätzparametern}
Die Stichprobengrösse wurde in der ersten Simulationsstudie über alle Bedingungen konstant gehalten. Dabei wurden wie bei McNeish 300 Klassen mit jeweils 50 Schulkindern mit den oben besprochenen Parametern simuliert \citeyearpar{mcneish2014analyzing}. In der Multilevel Literatur wird eine Mindestanzahl von 50 Gruppen empfohlen, damit die Schätzungen der Koeffizienten mittels hierarchischen linearen Modellen genau sind \citep{maashox2005samplesize}. Mit dieser grossen Stichprobengrösse wird sichergestellt, dass Ergebnisse auf die Manipulation der Parameter und nicht auf eine ungenügende Stichprobengrösse zurückzuführen sind.

Um die oben genannten Aussagen zu überprüfen, wurden zwei Kennwerte berechnet. Der erste Kennwert ist die relative Abweichung der geschätzten Regressionskoeffizienten $\widehat{\gamma}$ von den Populationsmittelwerten $\gamma$. Die Stärke dieser Abweichung wird in Prozent angegeben \citep{hooglandboosma1998robustness} und nach folgender Formel berechnet: 
\begin{equation}
\Delta\widehat{\gamma} = \dfrac{\widebar{\widehat{\gamma}} - \gamma}{\gamma}
\end{equation}
Dabei ist $\widebar{\widehat{\gamma}}$ der Mittelwert aller Regressionskoeffizienten aus einer Bedingung. Diese relative Abweichung wurde in beiden Designs für jede Analysemethode und in jeder IKK Bedingung für den Gesamtmittelwert $\gamma_{00}$ als auch für die Gesamtsteigung $\gamma_{10}$ resp. $\gamma_{01}$ berechnet. Gemäss Hoogland und Boomsma \citeyearpar{hooglandboosma1998robustness} gelten relative Abweichungen von kleiner als 5\% als akzeptabel.

Der zweite Kennwert beschreibt die Genauigkeit der Schätzung des Standardfehlers (engl. \textit{Standard Error}) und berechnet sich aus dem Verhältnis der Abweichung des mittleren Standardfehlers aus einer Bedingung von der Standardabweichung der Regressionskoeffizienten über alle 1000 Replikationen dieser Bedingung geteilt durch dieselbe Standardabweichung \citep{hooglandboosma1998robustness, mcneish2014analyzing}. Die Formel zur Berechnung sieht wie folgt aus:
\begin{equation}
\Delta\widehat{SE}_{\widehat{\gamma}} = \dfrac{\widebar{\widehat{SE}}_{\widehat{\gamma}} - \widehat{SD}_{\widehat{\gamma}}}{\widehat{SD}_{\widehat{\gamma}}}
\end{equation}
Der berechnete Wert beschreibt also wie bei der relativen Abweichung, um wie viel Prozent der geschätzte Standardfehler vom wahren Populationswert abweicht. Liegen Genauigkeitswerte über 0 gelten die Standardfehler als Überschätzt und liegen die Werte unter 0 werden Standardfehler unterschätzt.
Hoogland und Boomsma \citeyearpar{hooglandboosma1998robustness} bezeichnen jegliche Genauigkeitswerte, die um mehr als 0.10 von 0 abweichen als unakzeptabel. Die Genauigkeit des Standardfehlers wurde wieder in beiden Designs für jede Analysemethode und in jeder IKK Bedingung berechnet.

\subsubsection{Ergebnisse Studie 1}
Der erste Kennwert der untersucht wurde, war die relative Abweichung der Regressionskoeffizienten. Sowohl bei einer Intervention auf Level-1 als auch bei einer Intervention auf Level-2 schätzten LM als auch HLM die Regressionskoeffizienten des Achsenabschnittes und der Steigung in allen IKK Bedingungen mit einer relativen Abweichung von kleiner als $|\Delta\widehat{\gamma}| < .05$. Auch die Varianzen dieser relativen Abweichungen war in allen Bedingungen kleiner als $\sigma^2 < .01$. Diese Werte entsprechen in diesem Fall den Ergebnissen von Mundfrom und Schults \citeyearpar{mundfrom2002monte} und McNeish \citeyearpar{mcneish2014analyzing}.

Die Genauigkeit der Schätzung des Standardfehlers der beiden Regressionskoeffizienten $\widehat{\gamma}_{00}$ und $\widehat{\gamma}_{10}$ bzw. $\widehat{\gamma}_{01}$ kann für jede der beiden Methoden aus der Tabelle \ref{tab:se_eff_intercept} entnommen werden. Im ersten Simulationsdesign wurden die Standardfehler bei der Verwendung von LM mit einer Genauigkeit von $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = -.0511$ bis $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = -.8028$ geschätzt. Bei der Verwendung von HLM reichten die SE Genauigkeitswerte von $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = -.0366$ bis $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = .0201$ . Bei einer IKK von .00 zeigte sich bei beiden Methoden eine akzeptable Schätzgenauigkeit des Standardfehlers mit einer Genauigkeit von $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = -.0511$ bei LM und $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = -.0366$ bei HLM. Sobald aber die IKK anstieg, wurde die Schätzung bei LM zunehmend ungenauer. Aus Tabelle \ref{tab:se_eff_intercept} ist zu entnehmen, dass bereits ab einer IKK von .10 die Anforderungen von Hoogland und Boomsma \citeyearpar{hooglandboosma1998robustness} nicht mehr erfüllt sind bei Verwendung von LM. Mit Werten von $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = -.4599$ bis $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = -.8028$ weist LM eine klare Unterschätzung des Standardfehlers auf, die zu einer erhöhten Fehler Typ 1 Rate führt. Vergleicht man die SE Genauigkeit von HLM aus dem ersten Simulationsdesign, erkennt man, dass in keiner IKK Bedingung den Grenzwert von $|\Delta\widehat{SE}_{\widehat{\gamma}}| > .10$ überschritten wird. Es wurde sogar ein noch strengeres Kriterium von $|\Delta\widehat{SE}_{\widehat{\gamma}}| > .05$ in allen IKK Bedingungen erfüllt. Bei Verwendung von HLM lag im ersten Simulationsdesign also weder eine Unter- noch eine Überschätzung vor. Dementsprechend entstehen bei der Verwendung von HLM keine erhöhten Fehler Typ 1 und Fehler Typ 2 Raten.
\begin{table}[t!]
\centering
\setlength{\tabcolsep}{10pt}
\begin{threeparttable}
\caption{SE Genauigkeit beider Regressionskoeffizienten in beiden Simulationsdesigns und für jede Analysemethode in allen IKK Bedingungen.}
\begin{tabular}{lcccccccc}
\toprule 
& \multicolumn{4}{c}{$\Delta\widehat{SE}_{\widehat{\gamma}_{00}}$} 
& \multicolumn{4}{c}{$\Delta\widehat{SE}_{\widehat{\gamma}_{10}}$ bzw. $\Delta\widehat{SE}_{\widehat{\gamma}_{10}}$}\\
\cmidrule(lr){2-5} \cmidrule(lr){6-9}
		& 	\multicolumn{2}{c}{Design 1} & \multicolumn{2}{c}{Design 2} 
		& \multicolumn{2}{c}{Design 1} & \multicolumn{2}{c}{Design 2}\\
			\cmidrule(lr){2-3}  \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9}
IKK 	& 	  LM 			&  HLM 				&  LM 				&  HLM  			&  LM 				&  HLM 				&  LM 				&  HLM\\
		 	\midrule
.00 	&   -.0511\tnote{a}	&   -.0366\tnote{b} &   -.0181\tnote{b}	& 	-.0027\tnote{b} & -.0095\tnote{b} 	& -.0098\tnote{b}	&  .0056\tnote{b} 	&  .0213\tnote{b}\\ 
.05 	&  	-.4599 			&	 .0009\tnote{b}	&	-.4494			&	 .0244\tnote{b}	&  .0312\tnote{b}	&  .0053\tnote{b}	& -.4729			& -.0193\tnote{b}\\ 
.10 	&  	-.5963			&	-.0191\tnote{b}	&	-.5900			&	-.0061\tnote{b}	&  .0542\tnote{a}	&  .0001\tnote{b}	& -.5790			&  .0207\tnote{b}\\ 
.15 	&  	-.6510			&	 .0084\tnote{b}	&	-.6620			&	-.0241\tnote{b}	&  .0599\tnote{a}	& -.0226\tnote{b}	& -.6534			&  .0010\tnote{b}\\ 
.20 	&  	-.6894			&	 .0201\tnote{b}	&	-.6832			&	 .0396\tnote{b}	&  .1327	 		&  .0135\tnote{b}	& -.6896			&  .0187\tnote{b}\\ 
.25 	&   -.7257 			&	-.0029\tnote{b}	&	-.7180			&	 .0266\tnote{b}	&  .1720	 		&  .0159\tnote{b}	& -.7324			& -.0258\tnote{b}\\ 
.30 	&   -.7506 			&	-.0120\tnote{b}	&	-.7481			&	-.0016\tnote{b}	&  .1565	 		& -.0318\tnote{b}	& -.7472			&  .0016\tnote{b}\\ 
.40 	&  	-.7783			&	 .0057\tnote{b}	&	-.7787 			&	 .0059\tnote{b}	&  .3443	 		&  .0424\tnote{b}	& -.7758			&  .0191\tnote{b}\\ 
.50 	&   -.8028 			&	-.0045\tnote{b}	&	-.8014			&	 .0041\tnote{b}	&  .4186	 		&  .0044\tnote{b}	& -.7943			&  .0401\tnote{b}\\  
\bottomrule
\end{tabular}
\label{tab:se_eff_intercept}
\begin{tablenotes}
\item [a] $|\Delta\widehat{SE}_{\widehat{\gamma}}| < .10$
\item [b] $|\Delta\widehat{SE}_{\widehat{\gamma}}| < .05$
\end{tablenotes}
\end{threeparttable}
\end{table}

Beim zweiten Simulationsdesign weist das LM eine Schätzgenauigkeit von $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = -.0181$ bis $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = -.8014$ auf. Das HLM Schätzte den Standardfehler mit einer SE Genauigkeit von $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = -.0241$ bis $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = .0396$. Es zeigte sich bezüglich der Genauigkeit der Schätzung des Standardfehlers des Gesamtmittelwertes $\widehat{\gamma}_{00}$ ein ähnliches Bild wie beim ersten Simulationsdesign. Wieder wiesen beide Methoden bei einer IKK von .00 eine genau Schätzung des Standardfehlers von $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = -.0181$ bei LM und $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = -.0027$ bei HLM auf. Diese Genauigkeit nahm bei erhöhter IKK und Verwendung von LM wieder stark ab. In der vierten Spalte der Tabelle \ref{tab:se_eff_intercept} kann man erkennen, dass bei einer IKK von .05 nur noch eine SE Genauigkeit von $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = -.4494$ erreicht wird und schlussendlich bei einer IKK von .50 bis zu einer SE Genauigkeit von $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = -.8014$ abnimmt. Auch diese Werte weisen bei der Verwendung eines LM auf eine Unterschätzung des Standardfehlers hin, die wiederum zu einer erhöhten Fehler Typ 1 Rate führt. Betrachtet man die fünfte Spalte aus Tabelle \ref{tab:se_eff_intercept}, erkennt man dass auch im zweiten Simulationsdesign die Standardfehler des Gesamtmittelwerts durch ein HLM genau geschätzt werden. In allen Bedingungen wurde der Grenzwert von $|\Delta\widehat{SE}_{\widehat{\gamma}}| > .10$ nicht überschritten. Folglich kommt es auch im zweiten Simulationsdesign zu keiner Über- oder Unterschätzung des Standardfehlers des Gesamtmittelwertes $\widehat{\gamma}_{00}$ bei Verwendung von HLM.

Betrachtet man nun die SE Genauigkeiten der Gesamtsteigung $\widehat{\gamma}_{10}$ bzw. $\widehat{\gamma}_{10}$ aus Tabelle \ref{tab:se_eff_intercept}, reicht im ersten Simulationsdesign die Schätzgenauigkeit von LM von $\Delta\widehat{SE}_{\widehat{\gamma}_{10}} = -.0095$ bis $\Delta\widehat{SE}_{\widehat{\gamma}_{10}} = .4186$. Die Schätzgenauigkeit des HLM reichte von $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = -.0318$ bis $\Delta\widehat{SE}_{\widehat{\gamma}_{00}} = .0424$. Beide Methoden weisen wieder bei einer IKK von .00 eine genaue Schätzung des Standardfehlers auf. Das LM verzeichnete eine abnehmende Genauigkeit bei der Schätzung des Standardfehlers sobald die IKK zunahm, so dass der Standardfehler zunehmend überschätzt wurde. Allerdings überschritten die Schätzungen von LM bis zu einer IKK von .15 den Grenzwert von $|\Delta\widehat{SE}_{\widehat{\gamma}}| > .10$ nicht. Mit einer SE Genauigkeit von $\Delta\widehat{SE}_{\widehat{\gamma}_{10}} = .0599$ lag die SE Genauigkeit von LM bei einer IKK von .15 immer noch im von Hoogland und Boosmam \citeyearpar{hooglandboosma1998robustness} als akzeptabel definierten Bereich. Ab einer IKK von .20 wurde von LM im ersten Simulationsdesign der Standardfehler so stark überschätzt, dass er nicht mehr im akzeptablen Bereich lag. Diese Überschätzung des Standardfehlers mittels LM erreichte dann bei einer IKK von .50 mit $\Delta\widehat{SE}_{\widehat{\gamma}_{10}} = .4186$ den höchsten Wert. Grundsätzlich wies das LM also eine zunehmende Überschätzung des Standardfehlers auf, das zu einer erhöhten Fehler Typ 2 Rate führt, die schlussendlich in einer niedrigeren Power resultiert. 
\begin{figure}[t!]
\centering
\captionsetup{width=8cm}
\includegraphics[width=8cm, height=8cm]{se_genauigkeit_design1}
\caption{Genauigkeit der Schätzung des Standardfehlers der Gesamtsteigung für jede Methode in allen IKK Bedingungen im ersten Simulationsdesign.}
\label{fig:se_genauigkeit_design1}
\end{figure}
In Abbildung \ref{fig:se_genauigkeit_design1} wird dieser Zusammenhang noch einmal graphisch dargestellt. Wie in Abbildung \ref{fig:se_genauigkeit_design1} zu erkennen und aus Tabelle \ref{tab:se_eff_intercept} zu entnehmen ist, bleiben die geschätzten Standardfehler des HLM immer hinnerhalb des akzeptablen Bereiches und erfüllen auch in allen Bedingungen das noch strengere Kriterium von $|\Delta\widehat{SE}_{\widehat{\gamma}}| > .05$. Die Schätzungen des Standardfehlers sind daher auch noch bei einer hohen IKK von .50 mit $\Delta\widehat{SE}_{\widehat{\gamma}_{10}} = .0044$ im akzeptablen Bereich. Folglich kommt es bei der Analyse mit einem HLM zu keiner Unter- oder Überschätzung des Standardfehlers und führt dementsprechend zu keiner erhöhten Fehler Typ 1 oder Fehler Typ 2 Rate, die in einer tieferen Power resultiert.

Beim zweiten Simulationsdesign wurden die Standardfehler der Gesamtsteigung durch das LM mit einer Genauigkeit von $\Delta\widehat{SE}_{\widehat{\gamma}_{01}} = .0056$ bis $\Delta\widehat{SE}_{\widehat{\gamma}_{01}} = -.7943$ geschätzt. Das HLM schätzte die Standardfehler mit einer Genauigkeit von $\Delta\widehat{SE}_{\widehat{\gamma}_{01}} = -.0258$ bis $\Delta\widehat{SE}_{\widehat{\gamma}_{01}} = .0401$. Beide Analysemethoden weisen wieder eine genaue Schätzung des Standardfehlers bei einer IKK von .00 auf. Betrachtet man die Entwicklung der Schätzung des Standardfehlers durch das LM, erkennt man, dass die Standardfehler wieder mit zunehmender IKK unterschätzt werden. Bei einer IKK von .05 wird mit $\Delta\widehat{SE}_{\widehat{\gamma}_{01}} = -.4729$ der Grenzwert für eine akzeptable Abweichung bereits überschritten. Diese Unterschätzung steigt mit zunehmender IKK weiter an, bis hin zu einer SE Genauigkeit von $\Delta\widehat{SE}_{\widehat{\gamma}_{01}} = -.7943$ bei einer IKK von 0.50. In diesem Fall resultiert diese Unterschätzung des Standardfehlers wieder in einer erhöhten Fehler Typ 1 Rate.
\begin{figure}[t!]
\centering
\captionsetup{width=8cm}
\includegraphics[width=8cm, height=8cm]{se_genauigkeit_design2}
\caption{Genauigkeit der Schätzung des Standardfehlers der Gesamtsteigung für jede Methode in allen IKK Bedingungen im zweiten Simulationsdesign.}
\label{fig:se_genauigkeit_design2}
\end{figure}
In Abbildung \ref{fig:se_genauigkeit_design2} sind wieder beide Verläufe über die verschiedenen IKK Bedingungen abgebildet. Dabei lässt sich zum einen direkt die Unterschätzung des Standardfehlers durch das LM erkennen, aber auch dass das HLM wieder eine sehr genaue Geschätzung des Standardfehlers aufweist. Diese Werte sind in der letzten Spalte der Tabelle \ref{tab:se_eff_intercept} abgebildet und zeigen, dass bei Verwendung von einem HLM die Standardfehler wieder in allen Bedingungen den Grenzwert von $|\Delta\widehat{SE}_{\widehat{\gamma}}| > .10$ nicht überschreiten und sogar kleiner als das noch strengere Kriterium $|\Delta\widehat{SE}_{\widehat{\gamma}}| > .05$ sind. Es entsteht folglich wieder weder eine Unter- noch Überschätzung des Standardfehlers bei der Verwendung eines HLM in diesem Simulationsdesign und dies resultiert demnach in keiner erhöhten Fehler Typ 1 oder Fehler Typ 2 Rate.

\subsubsection{Diskussion Studie 1}
Mit der ersten Studie dieser Arbeit wurde überprüft, wie sich die Schätzgenauigkeit von Regressionskoeffizienten und Standardfehlern zwischen LM und HLM bei der Analyse von hierarchischen Daten unterscheidet, wie sich diese Schätzungen bei variierender IKK verhalten und ob die Ebene der Intervention einen Einfluss auf die Schätzgenauigkeit hat. 

Dabei konnte gezeigt werden, dass beide Methoden die Regressionskoeffizienten des Gesamtmittelwertes und der Gesamtsteigung über alle Bedingungen genau schätzten. Unterschiede in der Schätzgenauigkeit gab es erst bei der Schätzung der Standardfehler. So wurde der Standardfehler des Gesamtmittelwertes bei steigender IKK in beiden Simulationsdesigns bei Verwendung von LM zunehmend Unterschätzt. Nur in der Bedingung ohne Einfluss der Gruppenzugehörigkeit schätzte das LM den Standardfehler genau. Das HLM schätzte hingegen in allen Bedingungen und in beiden Simulationsdesigns die Standardfehler des Gesamtmittelwertes genau. Bei der Schätzung des Standardfehlers der Gesamtsteigung gab es bei der Verwendung von LM einen unterschied bezüglich des Simulationsdesigns. Im ersten Simulationsdesign wurde sobald die Gruppenzugehörigkeit einen Einfluss hatte, der Standardfehler mit steigender IKK zunehmend überschätzt. Beim zweiten Simulationsdesign wurde der Standardfehler bei steigender IKK zunehmend unterschätzt. Bei der Analyse mittels HLM wurden wieder in allen Bedingungen und in beiden Simulationsdesigns die Standardfehler der Gesamtsteigung genau geschätzt.

Diese Ergebnisse bedeuten, dass es je nach Fokus der Forschungsfrage einen entscheidenden Einfluss hat, ob man ein LM oder ein HLM verwendet. Interessiert man sich nur für die Ausprägung der Regressionskoeffizienten spielt die Wahl der Analysemethode also keine grosse Rolle. Zu dieser Erkenntnis kamen auch schon Autoren aus früheren Studien \citep{mcneish2014analyzing, mundfrom2002monte, osborne2000advantages} und diese wurde mit der vorliegenden Simulationsstudie noch einmal bestätigt. 

Eine weitere Schlussfolgerung, die aus diesen Ergebnissen gezogen werden kann, ist dass es sich empfiehlt hierarchische Daten mittels HLM zu analysieren um Ungenauigkeiten in der Schätzung des Standardfehlers und schlussendlich höhere Fehler Typ 1 oder Fehler Typ 2 Raten zu verhindern. Werden trotz dem Vorhandensein hierarchischer Strukturen mit LM gearbeitet, kann es je nach Studiendesign zu massiven Unter- oder Überschätzung der Standardfehler kommen und folglich zu verzerrten Studienergebnissen führen. Bei einer Unterschätzung des Standardfehlers laufen gemäss dieser Ergebnisse Forschende Gefahr, aufgrund der erhöhten Fehler Typ 1 Rate Effekte zu finden, die in Wahrheit gar nicht vorhanden sind. Diese Unterschätzung tritt vor allem dann auf, wenn Interventionen auf Level-2 durchgeführt wird und wurde ebenfalls bereits von Moerbeek et al. \citeyearpar{MOERBEEK2003341} mathematisch aufgezeigt. Zu einer Überschätzung des Standardfehlers und folglich zu einer erhöhten Fehler Typ 2 Rate kommt es, wenn bei einer Intervention auf Level-1 die hierarchische Struktur missachtet und mit einem LM analysiert wird. Dabei spielt es gemäss Moerbeek et al. \citeyearpar{MOERBEEK2003341} eine Rolle, ob von einer Interaktion zwischen Intervention und Gruppenzugehörigkeit ausgegangen wird oder nicht. Wird von keiner Interaktion ausgegangen, wie in unserer Simulationsstudie, werden Standardfehler von LM zunehmend Überschätzt. Wird hingegen bei der Anaylse eine Interaktion zwischen Intervention und Gruppenzugehörigkeit angenommen, kann es in Abhängigkeit der Varianzkomponenten und der Gruppengrössen zu einer Unter- oder Überschätzung des Standardfehlers führen \citep{MOERBEEK2003341}. 

Bis jetzt wurden allerdings nur die Schätzgenauigkeit der Regressionskoeffizienten und der Standardfehler besprochen und nicht die Effektive Power dieser Beiden Analysemethoden. Auch wenn aufgrund der Ergebnisse aus der ersten Simulationsstudie hervorgeht, dass eine Verwendung von HLM bei der Analyse von hierarchischen Daten zu genaueren Schätzungen und weniger Verzerrung der Prüfgrösse führt als LM, wäre es interessant zu beobachten wie sich die Power dieser beiden Methoden über die verschiedenen IKK Bedingungen verändert. 

\subsection{Studie 2: Statistische Power von HLM}
In der zweiten Studie wurde untersucht, wie zuverlässig LM und HLM einen Effekt einer Intervention finden, wenn dieser Effekt auch effektiv vorhanden ist. Die Fähigkeit einen Effekt zu finden, wenn er auch wirklich vorhanden ist wird Power genannt. Die Power steht in einem direkten Zusammenhang mit der Stichprobengrösse, so dass eine steigende Stichprobengrösse zu einer höheren Power führt \citep{snijders2005samplesizepower}. Folglich würde eine so grosse Stichprobe aus Studie 1 wahrscheinlich zu keinen Unterschieden in der Power zwischen den beiden Methoden führen. Allerdings ist es in der Praxis oft nicht möglich, eine solche grosse Stichprobe von insgesamt 15000 Beobachtungen zu erheben. Daher wird in dieser zweiten Studie eine etwas reduzierte und praxisnähere Stichprobengrösse für die beiden Studiendesigns simuliert. Die Anzahl simulierter Klassen wurde folglich auf 70 und die Klassengrösse auf 12 reduziert. Diese Reduktion führte zu einer Stichprobengrösse von insgesamt 840 Beobachtungen. 

Wie bereits in der Herleitung der Forschungsfrage beschrieben, wurde der Effekt des Treatments mit einem \textit{t} Test überprüft. Die Prüfgrösse berechnet sich aus folgender Formel:
\begin{equation}
t = \dfrac{\widehat{\gamma}}{\widehat{SE}_{\widehat{\gamma}}}
\end{equation}
Dabei ist $\widehat{\gamma}$ der jeweilige geschätzte Regressionskoeffizienten und $\widehat{SE}_{\widehat{\gamma}}$ der dazugehörige Standardfehler. Die Anzahl Freiheitsgrade wurde bei normalen linearen Modellen mittels der bekannten Formel $N + p - 1$ berechnet. Bei den hierarchischen linearen Modellen wurde die Satterthwaite Methode verwendet, um die Anzahl Freiheitsgrade zu bestimmen \citeyearpar{satter1941synthesis}. Die Satterthwaite Methode ist eine der in der Forschung diskutierten Methoden, die häufig zur Berechnung der Freiheitsgrade von hierarchischen linearen Modellen verwendet wird \citep{raudenbush2002hierarchical,SnijdersTomA.B2012Ma:a}. 

Um nun die Power zu berechnen, wurde in jeder Bedingung und für jede Analysemethode die Anzahl an Tests, die auf einem Signifikanzniveau von 5\% signifikant wurden, durch die Anzahl Replikationen pro Bedingung geteilt. Dies ergibt die prozentuale Häufigkeit, bei der die Analysemethode in der gegebenen IKK Bedingung einen signifikanten Effekt gefunden hat. Da im Simulationsdesign die Intervention in der Tat einen Effekt hat, entspricht diese prozentuale Häufigkeit der Power dieser Analysemethode.

\subsubsection{Ergebnisse Studie 2}
Die Ergebnisse der zweiten Simulationsstudie werden in Tabelle \ref{tab:power_study2} abgebildet. 
\begin{table}[t!]
\centering
\setlength{\tabcolsep}{10pt}
\begin{threeparttable}
\caption{Statistische Power in beiden Simulationsdesigns für jede Analysemethode in allen IKK Bedingungen.}
\begin{tabular}{lcccc}
\toprule
	& \multicolumn{4}{c}{Statistische Power}\\
\cmidrule(lr){2-5}
	& \multicolumn{2}{c}{Design 1} & \multicolumn{2}{c}{Design 2} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
IKK & LM 	& HLM 	& LM 	& HLM \\ 
\midrule
.00 & .76 	& .76 	& .74 	& .72 \\ 
.05 & .72 	& .75 	& .71 	& .53 \\ 
.10 & .73 	& .76 	& .64 	& .38 \\ 
.15 & .72 	& .78 	& .64 	& .34 \\ 
.20 & .67 	& .75 	& .56 	& .24 \\ 
.25 & .69 	& .78 	& .56 	& .21 \\ 
.30 & .62 	& .78 	& .57 	& .19 \\ 
.40 & .54 	& .77 	& .56 	& .13 \\ 
.50 & .44 	& .76 	& .55 	& .10 \\ 
\bottomrule
\end{tabular}
\label{tab:power_study2}
\end{threeparttable}
\end{table}
Es ist zu beachten, dass nur die Power für die Gesamtsteigung $\widehat{\gamma}_{10}$ bzw. $\widehat{\gamma}_{10}$ berechnet wurde, weil diese Regressionskoeffizienten auch den Effekt der Intervention abbilden. Im ersten Simulationsdesign in dem die Intervention auf Level-1 durchgeführt wurde, reicht die Power des LM von $.44$ bis $.76$. Dabei ist zu beachten, dass bei einer IKK von .00 die höchste Power von $.76$ erreicht wird und mit zunehmender IKK abnimmt. In Abbildung \ref{fig:power_design1} sind die einzelnen Power-Werte jeder IKK Bedingung und für jede Analysemethode abgebildet. Dabei lässt sich erkennen, dass die Power von LM bis zu einer IKK von .10 noch einigermassen mit der Power von HLM mithalten kann. Sobald aber die IKK grösser als .10 ist lässt sich eine kontinuierliche Abnahme der Power beobachten. Betrachtet man die Schätzgenauigkeit des Standardfehlers von LM an dieser Stelle, erkennt man, dass ab einer IKK von .15 mit $\Delta\widehat{SE}_{\widehat{\gamma}_{10}} = 0.1167$ den Grenzwert von $|\Delta\widehat{SE}_{\widehat{\gamma}}| > .10$ \citep{hooglandboosma1998robustness} überschritten wird und folglich die Schätzung des Standardfehlers als nicht mehr akzeptabel gilt. Dies führt zu einer zu hohen Fehler Typ 1 Rate, die schlussendlich  in dieser tieferen Power resultiert. Die Power unter Verwendung des HLM reicht von $.75$ bis $.78$ und bleibt gemäss Abbildung \ref{fig:power_design1} über alle Bedingungen relativ konstant. Die Schätzgenauigkeit der Standardfehler mittels HLM überschreitet in keiner IKK Bedingung den Grenzwert von $|\Delta\widehat{SE}_{\widehat{\gamma}}| > .10$. Bei einer Analyse mit HLM kommt es in diesem Fall also weder zu einer Über- noch einer Unterschätzung des Standardfehlers.
\begin{figure}[t!]
\centering
\captionsetup{width=8cm}
\includegraphics[width=8cm, height=8cm]{power_design1}
\caption{Statistische Power von ML und HLM in den verschiedenen IKK Bedingungen bei einer Intervention auf Level-1.}
\label{fig:power_design1}
\end{figure}

Im zweiten Simulationsdesign bei dem die Intervention auf Level-2 durchgeführt wurde, reicht die Power des LM von $.55$ bis $.74$ und nimmt wieder mit steigender IKK ab. Die Power des HLM reicht im zweiten Simulationsdesign von $.10$ bis $.72$ und verzeichnete ebenfalls eine Abnahme der Power mit zunehmender IKK. In Abbildung \ref{fig:power_design2} ist dieser Verlauf noch einmal Visualisiert. Dabei kann man erkennen, dass die Abnahme der Power bei einer zunehmenden IKK bei einer Analyse mittels HLM stärker als bei einer Analyse mittels LM ist. Bei einer IKK von .50 erreichten HLM nur noch eine Power von $.10$ wobei LM eine Power von $.55$ erreichten. Die Schätzgenauigkeiten des Standardfehlers werden ähnlich wie in Studie 1 von LM ab einer IKK von .005 stark unterschätzt und überschreiten in allen weiteren IKK Bedingungen den Grenzwert von $|\Delta\widehat{SE}_{\widehat{\gamma}}| > .10$. Diese Unterschätzung der Standardfehler durch LM führt zu dieser vermeintlich besseren Power, da die Fehler Typ 1 Rate durch die Unterschätzung erhöht ist. Die Schätzung der Standardfehler bleibt bei der Verwendung von HLM im akzeptablen Bereich und überschreiten den Grenzwert in keiner IKK Bedingung. 
\begin{figure}[t!]
\centering
\captionsetup{width=8cm}
\includegraphics[width=8cm, height=8cm]{power_design2}
\caption{Statistische Power von ML und HLM in den verschiedenen IKK Bedingungen bei einer Intervention auf Level-2.}
\label{fig:power_design2}
\end{figure}

\subsubsection{Diskussion Studie 2}
Die zweite Simulationsstudie untersuchte, wie genau sich die Power bezüglich eines Effekts einer Intervention zwischen den beiden Analysemethoden unterscheidet und vor allem wie sich die Power über die verschiedenen IKK Bedingungen verändert. Wie in der ersten Studie wurde auch in der zweiten Studie zwischen zwei Simulationsdesigns unterschieden bei denen die Intervention zum einen auf Level-1 und zum anderen auf Level-2 durchgeführt wurde.

Im ersten Studiendesign bestätigte sich die Vermutung aus der vorherigen Studie, dass bei einer Intervention auf Level-1 ohne Interaktion zwischen Gruppenzugehörigkeit und Intervention die Power mit zunehmender IKK abnimmt, wenn bei der Analyse LM verwendet wird. Wird an Stelle von LM ein HLM verwendet bleibt die Power über alle IKK Bedingungen Konstant. Im zweiten Simulationsdesign zeigte sich allerdings eine Abnahme der Power bei beiden Analysemethoden bei zunehmender IKK. Diese Abnahme war bei der Verwendung von LM geringer als bei der Verwendung von HLM.

Interessiert sich nun eine Forschungsfrage für den Effekt einer Intervention, lässt sich aus diesen Ergebnissen zwei Schlussfolgerungen ziehen. Zum einen ist es Ratsam, wenn immer möglich die Intervention auf Level-1 durchzuführen, da die Power im zweiten Simulationsdesign bei beiden Analysemethoden mit steigender IKK stark abnahm. Diese Erkenntnis stimmt mit den Aussagen aus der Literatur überein, dass eine Intervention auf Level-2 es erschwert, den Effekt der Intervention von dem Effekt der Gruppenzugehörigkeit zu trennen, da in diesem Studiendesign keine Beobachtungen aus Kontroll- und Interventionsgruppe in der selben Level-2 Einheit vorhanden sind \citep{cleary2012studydesign, moerbeek2000design}. 

Zum andren sollte grundsätzlich ein HLM zur Analyse von hierarchischen Daten verwendet werden, da sich die Power bei einer Intervention auf Level-1 auch bei hoher IKK nicht verschlechtert. Ist es den Forschenden jedoch nicht möglich eine Intervention auf Level-1 durchzuführen, könnte man aus den Ergebnissen dieser zweiten Studie schliessen, dass ein LM im zweiten Studiendesign eine bessere Power als das HLM vorzuweisen. Da in der ersten Studie gezeigt wurde, dass in dieser Situation der Standardfehler vom LM stark unterschätzt wird, kann diese schwache Abnahme der Power auf die erhöhte Fehler Typ 1 Rate und die Inflation der signifikanten Tests zurückgeführt werden. Da es bei der Analyse mittels HLM zu keiner Verzerrung der Schätzung des Standardfehlers kommt, kann der Power von HLM mehr Vertrauen geschenkt werden. Mit dieser Information könnten nun Forschende die Analysemethode als Ursache für diese tiefe Power ausschliessen und nach anderen Gründe suchen, die zu dieser tiefen Power führen (z.B. Studiendesign oder Stichprobengrösse).

In der folgenden abschlissenden Diskussion dieser Arbeit werden die bereits besprochenen Ergebnisse noch einmal kurz aufgegriffen und es werden mögliche weitere Forschungsfragen, sowie Limitationen dieser Simulationsstudie besprochen.

\subsection{Abschliessende Diskussion}
Mit diesen beiden Studien wurde das Ziel verfolgt, die Unterschiede zwischen der Schätz-genauigkeit von Regressionskoeffizienten und deren Standardfehlern sowie die daraus resultierende Power von LM und HLM zu untersuchen. Auch wenn die Regressionskoeffizienten von beiden Methoden genau geschätzt wurden, konnten die Studien zeigen, dass HLM auch bei hoher Abhängigkeit der Gruppenzugehörigkeit genaue Schätzungen der Standardfehler liefern, wohingegen ein LM bei steigender IKK eine immer stärkere Verzerrung der Schätzung aufweist. Dementsprechend führten Analysen mittels HLM auch zu keiner Verzerrung der Power bei der Testung von Interventionseffekten.

Die aus dieser Simulationsstudie resultierende Erkenntnis, dass HLM einen klaren Vorteil gegenüber LM bei der Analyse von hierarchischen Daten vorweisen, ist keine Neuheit und wurde in einigen Studien bereits gefunden \citep{mcneish2014analyzing, MOERBEEK2003341, mundfrom2002monte, osborne2000advantages}. Dennoch konnte diese Studie, die in Moerbeek et al. \citeyearpar{MOERBEEK2003341} verwendeten Studiendesigns, in eine Simulationsstudie integrieren, um den Einfluss dieser beiden Interventionsformen auf die Schätzgenauigkeit von LM und HLM zu untersuchen. Damit können klare Empfehlungen für die Forschung mit hierarchischen Daten abgeleitet werden. Beispielsweise sollte wenn immer möglich eine Intervention auf Level-1 durchgeführt werden, um Effekte der Gruppenzugehörigkeit von Effekten der Intervention trennen zu können. 

In manchen Fällen ist es allerdings nicht möglich die Intervention auf Level-1 durchzuführen und benötigen daher eine Intervention auf Level-2, um eine Kontamination der Interventionsgruppe zu vermeiden. Wie man in der zweiten Studie beobachten konnte, verringerte sich die Power des HLM bei einer Intervention auf Level-2 bei einer Zunahme der IKK enorm. Weiterführende Simulationsstudien könnten nun untersuchen, welche Möglichkeiten es gibt diese Power zu verbessern. Da in der aktuellen Simulationsstudie nur die IKK variiert wurde und bekanntlicher weise die Power mit steigender Stichprobengrösse zunimmt, könnten weitere Studien untersuchen, wie gross eine Stichprobe sein müsste, damit ein HLM auch bei einer Intervention auf Level-2 eine akzeptable Power hat. Allgemein wäre es interessant zu untersuchen, wie sich eine variierende Stichprobengrösse auf die Schätzgenauigkeit oder auf die Power von HLM auswirkt und ob es eine Interaktion zwischen IKK und Stichprobengrösse gibt.

Es gibt natürlich auch weitere Methoden als HLM die zur Analyse von hierarchischen Daten geeignet sind. Zu diesen Methoden gehört unter anderem GEE (engl. \textit{Generalised Estimating Equation}), die oft für Längsschnittstudien verwendet wird \citep{hardin2005gee, liang1986gee}. 




Powerstudie wurde nur mit fixer Stichprobengrösse und fixierter Effektgrösse durchgeführt. Interessant wäre hier eine weiterführung, bei dem stichprobengrösse und oder Effektgrösse variiert werden. (vlt. inkl. variierender IKK)

grenzwert wieso 10 prozent? 5prozent besser? in power studie hat man gesehen, dass auch schon eine 5prozentige abweichung zu einer verschlechterung der power geführt hatte.


\subsection{Shiny App zur Simulationsstudie}
























































\newpage
\singlespacing

\bibliography{literatur_masterarbeit}
\bibliographystyle{apacite}

\section{Anhang}
\appendix
\section{R Code}





\end{document}

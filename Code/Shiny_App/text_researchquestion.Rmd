---
title: "researchquestion"
author: "noah"
date: "23 3 2020"
output: html_document
---

#### Forschungsfrage
Werden hierarchische Daten mit normalen linearen Modellen (LM) und nicht mit einem hierarchischen linearen Modell (HLM) analysiert, kann dies zu Fehlschlüssen in den Ergebnissen führen. 

In der frühere Forschung hat sich gezeigt, dass wenn LMs zur Analyse verwendet werden die Grösse der Regressionskoeffizienten auch bei grossem Einfluss der Klassenzugehörigkeit vom Modell genau geschätzt werden kann (McNeish, 2014; Mundfrom & Schults, 2002). 

Allerdings interessiert man sich in der Forschung oft nicht nur für die Grösse des Effekts, sondern auch ob dieser einen signifikanten Einfluss hat. Um dies zu überprüfen, werden üblicherweise *t* Tests durchgeführt (Snijders & Bosker, 2012). Die Prüfgrösse des *t* Tests wird über das Verhältnis zwischen dem geschätzten Regressionskoeffizienten und dessen Standardfehlers bestimmt. Wird beispielsweise ein Standardfehler zu klein geschätzt, steigt die Prüfgrösse an und die Rate mit der die Nullhypothese abgelehnt wird, nimmt zu. Wird der Standardfehler zu gross geschätzt, verkleinert sich die Prüfgrösse und die Rate mit der die Alternativhypothese abgelehnt wird, nimmt zu. Folglich führt eine Unterschätzung des Standardfehlers zu einer erhöhten Fehler Typ 1 Rate und eine Überschätzung zu einer erhöhten Fehler Typ 2 Rate und somit zu einer geringeren Power (Snijders & Bosker, 2012). Unter Power wird die Wahrscheinlichkeit verstanden, einen Effekt zu finden, wenn dieser auch effektiv in der Population vorhanden ist (Scherbaum & Ferreter, 2009). Daher ist eine genaue Schätzung des Standardfehlers umso wichtiger, da dieser massgeblich zur Power des Tests beiträgt. Da der Standardfehler in einem direkten Zusammenhang mit der Stichprobengrösse steht und grössere Stichproben zu kleineren Standardfehlern führen, ist die Wahl der Stichprobengrösse ein entscheidender Faktor (James et al., 2013, Snijders & Bosker, 2012). Bei hierarchischen Daten ist die effektive Stichprobe verkleinert, da sich Beobachtungen innerhalb der selben Gruppe zueinander ähnlicher sind als zu anderen Beobachtungen (Raudenbusch & Bryk, 2002). Da ein HLM die hierarchische Struktur berücksichtigt und ein LM nicht, arbeiten diese Methoden mit unterschiedlichen Stichprobengrössen und müssten folglich zu unterschiedlichen Standardfehlern und dementsprechend auch zu verschiedenen Prüfgrössen für den *t* Test gelangen. 

Diese Erkenntnis bestätigte sich schon in mehreren Simulationsstudien und theoretischen Artikeln \citep[z.B.][]{guo2005groupeddatahlm, krullmackinnon2010mediation, mcneish2014analyzing, MOERBEEK2003341}. Dabei ergab sich in diesen Artikeln, dass der Standardfehler in Abhängigkeit des Studiendesigns und der Analyseart von LMs unter- oder überschätzt wird. Beispielsweise fanden Krull und MacKinnon \citeyearpar{krullmackinnon2010mediation}, dass die Standardfehler eines Mediationseffekts konstant von LMs unterschätzt wurden und folglich zu einer erhöhten Fehler Typ 1 Rate führten. Diese Unterschätzung stieg mit zunehmender IKK sogar noch weiter an \citep{krullmackinnon2010mediation}. McNeish \citeyearpar{mcneish2014analyzing} fand ebenfalls, dass der Standardfehler des Achsenabschnittes von LMs konstant unterschätzt wurde und bei zunehmender IKK die Unterschätzung extremer wurde. Allerdings wurde der Standardfehler nicht immer unterschätzt. Moerbeek et al. \citeyearpar{MOERBEEK2003341} konnten in ihrem Artikel an einem simulierten und an einem realen Datensatz zeigen, dass der Standardfehler eines Interventionseffekts je nach Studiendesign von LMs unter- oder überschätzt wurde. Wird eine Intervention auf Level-1 durchgeführt, d.h. die zufällige Zuweisung zu einer Interventions- oder Kontrollgruppe geschieht auf der Individualebene, können Standardfehler durch LM überschätzt werden und folglich zu einer niedrigeren Power führen \citep{MOERBEEK2003341}. Wird eine Intervention auf Level-2 durchgeführt und die zufällige Zuweisung zu einer Interventions- oder Kontrollgruppe findet auf der Gruppenebene statt, führte dies wieder zu einer Unterschätzung des Standardfehlers \citep{MOERBEEK2003341}. In all diesen Studien konnte allerdings gezeigt werden, dass HLMs nicht diesen Limitationen unterlagen und den Standardfehler durchgehend genau geschätzt haben.

Neben der Prüfgrösse ist auch die Anzahl an Freiheitsgrade relevant, um die Signifikanz eines Effekts mittels \textit{t} Test zu überprüfen. Während bei normalen LMs die Anzahl Freiheitsgrade durch $N - p - 1$ bestimmt wird, wobei $N$ die Stichprobengrösse und $p$ die Anzahl Parameter im Modell sind, ist die Berechnung der Freiheitsgrade bei HLMs nicht eindeutig geklärt und ein aktueller Forschungsgegenstand \citep{mcneish2014analyzing,raudenbush2002hierarchical,SnijdersTomA.B2012Ma:a}.

Wie man in den vorherigen Studien erkennen kann, gibt es viele Faktoren, die einen Einfluss auf die Grösse des Standardfehlers haben. Um diese Einflüsse zu untersuchen werden zwei Simulationsstudien durchgeführt. Das Ziel der ersten Simulationsstudie ist es Teile dieser vorherigen Studien zu replizieren. Dabei wird der Einfluss von der IKK und des Studiendesigns auf die Schätzgenauigkeit der Regressionskoeffizienten und des Standardfehlers von LMs und HLMs untersucht. Gemäss der vorherigen Studien von Krull und MacKinnon \citeyearpar{krullmackinnon2010mediation} und McNeish \citeyearpar{mcneish2014analyzing} wird erwartet, dass bei zunehmender IKK die Schätzgenauigkeit von LMs abnimmt, bei HLMs aber konstant bleibt. Ausserdem wird davon ausgegangen, dass der Standardfehler des Interventionseffekts bei einer Intervention auf Level-1 gemäss Moerbeek et al. \citeyearpar{MOERBEEK2003341} überschätzt wird, sofern keine Interaktion zwischen Intervention und Gruppenzugehörigkeit angenommen wird. Ebenfalls wird angenommen, dass bei einer Intervention auf Level-2 der Standardfehler des Interventionseffekts durch LMs wieder unterschätzt wird. In beiden Simulationsdesigns wird gemäss Moerbeek et al. \citeyearpar{MOERBEEK2003341} erwartet, dass HLMs eine konstant genaue Schätzung der Standardfehler vorweisen.

Wie bereits erläutert führen zu klein geschätzte Standardfehler zu einer erhöhten Fehler Typ 1 Rate. Diese erhöhte Fehler Typ 1 Rate resultiert folglich in auffällig kleinen $p$-Werten \citep{raudenbush2002hierarchical, SnijdersTomA.B2012Ma:a}. In einer Studie von Guo \citeyearpar{guo2005groupeddatahlm} wurde gezeigt, dass ein $p$-Wert eines Effekts der basierend auf auf einem LM berechnet wurde, halb so gross war, wie der $p$-Wert eines HLMs. Dies führte dazu, dass ein LM diesen Effekt als signifikant und ein HLM als nicht signifikant identifizierten \citep{guo2005groupeddatahlm}. Aber auch das Gegenteil ist ein Problem. Werden Standardfehler Überschätzt erhöht sich die Fehler Typ 2 Rate und die Power verkleinert sich. In seinem Artikel erwähnte Guo ebenfalls, dass vor allem bei der Suche nach kleinen Effektstärken oder bei kleineren Stichproben die Gefahr besteht, dass ein LM zu fehlerhaften Ergebnissen gelangt \citep{guo2005groupeddatahlm}. Diese Schätzungenauigkeiten können also zu fehlerhaften Schlussfolgerungen führen und es sollte folglich im Interesse jedes Forschenden sein, diese zu vermeiden. 

Folglich wird in einer zweiten kleineren Simulationsstudie untersucht, wie sich die Power dieser beiden Analysemethoden bei einer kleineren Stichprobe und in Abhängigkeit der IKK verhält. Wie in der ersten Simulationsstudie, werden auch in der zweiten Simulationsstudie die beiden Interventionsdesigns von Moerbeek et al. \citeyearpar{MOERBEEK2003341} untersucht. Dabei werden bei einem Interventionsdesign auf Level-1 grundsätzlich eine höhere Power erwartet, da in diesem Design der Effekt der Gruppenzugehörigkeit vom Effekt der Intervention getrennt werden kann \citep{moerbeek2000design}. Ebenfalls wird erwartet, dass die Power von LM bei einer Intervention auf Level-1 mit zunehmender IKK abnimmt, da angenommen wird, dass es zunehmend zu einer Überschätzung des Standardfehlers kommt und dieser zu einer erhöhten Fehler Typ 1 Rate führt. Die Power eines HLMs sollte aber über alle IKK Bedingungen konstant bleiben, da gemäss den besprochenen Studien ein HLM auch bei zunehmender IKK den Standardfehler genau schätzt \citep{mcneish2014analyzing}. Bei einer Intervention auf Level-2 werden aufgrund des Interventionsdesigns grundsätzlich bei beiden Analysemethoden keine hohe Power erwartet \citep{moerbeek2000design}. Allerdings wird erwartet, dass die Power von LMs höher als die Power von HLMs ist, da gemäss Moerbeek et al. \citeyearpar{MOERBEEK2003341} in dieser Situation die Standardfehler von LMs zunehmend unterschätzt werden. 
#### Studie 1: Genauigkeit von Schätzparametern
Die Stichprobengrösse wurde in der ersten Simulationsstudie über alle Bedingungen konstant gehalten. Dabei wurden wie bei McNeish 300 Klassen mit jeweils 50 Schulkindern mit den oben besprochenen Parametern simuliert \citeyearpar{mcneish2014analyzing}. In der Multilevel Literatur wird eine Mindestanzahl von 50 Gruppen empfohlen, damit die Schätzungen der Koeffizienten mittels hierarchischen linearen Modellen genau sind \citep{maashox2005samplesize}. Mit dieser viel grösseren Stichprobengrösse wird sichergestellt, dass Ergebnisse auf die Manipulation der Parameter und nicht auf eine ungenügende Stichprobengrösse zurückzuführen sind.

Um die oben getroffenen Annahme zu überprüfen, dass ein HLM als auch ein LM die Regressionskoeffizienten bei sich verändernder IKK genau schätzen, wird die relative Abweichung der geschätzten Regressionskoeffizienten $\widehat{\gamma}$ von den Populationsmittelwerten $\gamma$ berechnet. Die Stärke dieser Abweichung wird in Prozent angegeben \citep{hooglandboosma1998robustness} und nach folgender Formel berechnet: 
$$
\begin{equation}
\Delta\widehat{\gamma} = \dfrac{\bar{\widehat{\gamma}} - \gamma}{\gamma}
\end{equation}
$$
Dabei ist $\bar{\widehat{\gamma}}$ der Mittelwert aller Regressionskoeffizienten aus einer Bedingung. Diese relative Abweichung wurde in beiden Designs für jede Analysemethode und in jeder IKK Bedingung für den Gesamtmittelwert $\gamma_{00}$ als auch für die Gesamtsteigung $\gamma_{10}$ resp. $\gamma_{01}$ berechnet. Gemäss Hoogland und Boomsma \citeyearpar{hooglandboosma1998robustness} gelten relative Abweichungen von kleiner als 5\% als akzeptabel. Alle weiteren Werte die eine Abweichung von mehr als 5\% aufweisen gelten folglich als ungenau und sollten nicht verwendet werden.

Um nun auch noch die Annahme zu überprüfen, dass der Standardfehler von HLM auch bei zunehmender IKK genau geschätzt wird und die Schätzung des Standardfehlers eines LMs immer ungenauer wird, muss ein weiterer Kennwert berechnet werden. Dieser Kennwert beschreibt die Genauigkeit der Schätzung des Standardfehlers und berechnet sich aus dem Verhältnis der Abweichung des mittleren Standardfehlers aus einer Bedingung von der Standardabweichung der Regressionskoeffizienten über alle 1000 Replikationen dieser Bedingung, geteilt durch dieselbe Standardabweichung \citep{hooglandboosma1998robustness, mcneish2014analyzing}. Die Formel zur Berechnung sieht wie folgt aus\footnote{SE ist die Abkürzung von \textit{Standard Error}, der englischen Bezeichnung für Standardfehler}:
$$
\begin{equation}
\Delta\widehat{SE}_{\widehat{\gamma}} = \dfrac{\bar{\widehat{SE}}_{\widehat{\gamma}} - \widehat{SD}_{\widehat{\gamma}}}{\widehat{SD}_{\widehat{\gamma}}}
\end{equation}
$$
Der berechnete Wert beschreibt also wie bei der relativen Abweichung, um wie viel Prozent der geschätzte Standardfehler vom wahren Populationswert abweicht. Liegen Genauigkeitswerte über 0 gelten die Standardfehler als Überschätzt und liegen die Werte unter 0 werden Standardfehler unterschätzt.
Hoogland und Boomsma \citeyearpar{hooglandboosma1998robustness} bezeichnen jegliche Genauigkeitswerte, die um mehr als 0.10 von 0 abweichen als unakzeptabel. Die Genauigkeit des Standardfehlers wurde wieder in beiden Designs für jede Analysemethode und in jeder IKK Bedingung berechnet.

#### Studie 2: Statistische Power von HLM

In der zweiten Studie wurde untersucht, wie zuverlässig LM und HLM einen Effekt einer Intervention finden, wenn dieser Effekt auch effektiv vorhanden ist. Die Fähigkeit einen Effekt zu finden, wenn er auch wirklich vorhanden ist wird Power genannt. Die Power steht in einem direkten Zusammenhang mit der Stichprobengrösse, so dass eine steigende Stichprobengrösse zu einer höheren Power führt \citep{snijders2005samplesizepower}. Folglich würde eine so grosse Stichprobe aus Studie 1 wahrscheinlich zu keinen Unterschieden in der Power zwischen den beiden Methoden führen. Allerdings ist es in der Praxis oft nicht möglich, eine solche grosse Stichprobe von insgesamt 15000 Beobachtungen zu erheben. Daher wird in dieser zweiten Studie eine etwas reduzierte und praxisnähere Stichprobengrösse für die beiden Studiendesigns simuliert. Die Anzahl simulierter Klassen wurde folglich auf 70 und die Klassengrösse auf 12 reduziert. Diese Werte entsprechen nun  den festgelegten Werte aus der Simulation von Moerbeek et al. \citeyearpar{MOERBEEK2003341}, die aus dem Datensatz des \textit{TVSFP} entnommen wurden \citep{FLAY1995smoking}. Diese Reduktion führte zu einer Stichprobengrösse von insgesamt 840 Beobachtungen. 

Wie bereits in der Herleitung der Forschungsfrage beschrieben, wurde der Effekt des Treatments mit einem \textit{t} Test überprüft. Die Prüfgrösse berechnet sich aus folgender Formel:
$$
\begin{equation}
t = \dfrac{\widehat{\gamma}}{\widehat{SE}_{\widehat{\gamma}}}
\end{equation}
$$
Dabei ist $\widehat{\gamma}$ der jeweilige geschätzte Regressionskoeffizienten und $\widehat{SE}_{\widehat{\gamma}}$ der dazugehörige Standardfehler. Die Anzahl Freiheitsgrade wurde bei normalen linearen Modellen mittels der bekannten Formel $N + p - 1$ berechnet. Bei den hierarchischen linearen Modellen wurde die Satterthwaite Methode verwendet, um die Anzahl Freiheitsgrade zu bestimmen \citeyearpar{satter1941synthesis}. Die Satterthwaite Methode ist eine der in der Forschung diskutierten Methoden, die häufig zur Berechnung der Freiheitsgrade von hierarchischen linearen Modellen verwendet wird \citep{raudenbush2002hierarchical,SnijdersTomA.B2012Ma:a}. 

Um nun die Power zu berechnen, wurde in jeder Bedingung und für jede Analysemethode die Anzahl an Tests, die auf einem Signifikanzniveau von 5\% signifikant wurden, durch die Anzahl Replikationen pro Bedingung geteilt. Dies ergibt die prozentuale Häufigkeit, bei der die Analysemethode in der gegebenen IKK Bedingung einen signifikanten Effekt gefunden hat. Da im Simulationsdesign die Intervention in der Tat einen Effekt hat, entspricht diese prozentuale Häufigkeit der Power dieser Analysemethode.